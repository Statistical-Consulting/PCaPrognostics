---
title: "models_on_test_cohorts"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r load packages}
library(dplyr)
library(ggplot2)
library(readr)
library(tidyr)
```
```{r load and prep data}

ov_results_cBoost <- as.data.frame(read_csv('../results_modelling_ovs/ov_GBoost.csv', lazy = TRUE))
ov_results_coxPas <- as.data.frame(read_csv('../results_modelling_ovs/ov_coxPAS.csv', lazy = TRUE))
ov_results_coxph <- as.data.frame(read_csv('../results_modelling_ovs/ov_coxph.csv', lazy = TRUE))
ov_results_DeepSurv <- as.data.frame(read_csv('../results_modelling_ovs/ov_DeepSurv.csv', lazy = TRUE))
ov_results_prio <- as.data.frame(read_csv('../results_modelling_ovs/ov_prio.csv', lazy = TRUE))
ov_results_rsf <- as.data.frame(read_csv('../results_modelling_ovs/ov_rsf.csv', lazy = TRUE))

ordered_datasets <- c("AutoEncoder", "pData_AutoEncoder", "Imputed", "pData_Imputed", "Intersection", "pData_Intersection", "pData")
# Reorder the dataset column and sort the data frame accordingly
ov_results_cBoost <- ov_results_cBoost %>%
  mutate(dataset = factor(dataset, levels = ordered_datasets)) %>%
  arrange(dataset)
ov_results_coxph <- ov_results_coxph %>%
  mutate(dataset = factor(dataset, levels = ordered_datasets)) %>%
  arrange(dataset)
ov_results_DeepSurv <- ov_results_DeepSurv %>%
  mutate(dataset = factor(dataset, levels = ordered_datasets)) %>%
  arrange(dataset)
ov_results_rsf <- ov_results_rsf %>%
  mutate(dataset = factor(dataset, levels = ordered_datasets)) %>%
  arrange(dataset)

ov_results_cBoost$dataset <- ordered_datasets
ov_results_coxph$dataset <- ordered_datasets
ov_results_DeepSurv$dataset <- ordered_datasets
ov_results_rsf$dataset <- ordered_datasets
# Select rows correpsonding to expression data sets
ov_results_cBoost_exprs_models <- ov_results_cBoost[c(1, 3, 5),]
ov_results_coxph_exprs_models <- ov_results_coxph[c(1, 3, 5),]
ov_results_DeepSurv_exprs_models <- ov_results_DeepSurv[c(1, 3, 5),]
ov_results_rsf_exprs_models <- ov_results_rsf[c(1, 3, 5),]
ov_results_prio_exprs_models <- ov_results_prio[2,]
```


```{r Defining model subsets}

all_models <- c("GBoost", "CoxPN", "CoxPH", "DeepSurv","PrioLasso", "RSF")

models_expr_based_only <- c("GBoost", "CoxPH","DeepSurv" ,"PrioLasso", "RSF")
```

```{r Create Best Performancing Models Vectors}
## All Models
# Based on training performance
best_training_perf_models <-  c(ov_results_cBoost[ov_results_cBoost$mean==max(ov_results_cBoost$mean), c("dataset")], 
                                        ov_results_coxPas[ov_results_coxPas$mean==max(ov_results_coxPas$mean), c("dataset")],
                                        ov_results_coxph[ov_results_coxph$mean==max(ov_results_coxph$mean), c("dataset")],
                                        ov_results_DeepSurv[ov_results_DeepSurv$mean==max(ov_results_DeepSurv$mean), c("dataset")],
                                        ov_results_prio[ov_results_prio$mean==max(ov_results_prio$mean), c("dataset")],
                                        ov_results_rsf[ov_results_rsf$mean==max(ov_results_rsf$mean), c("dataset")])
names(best_training_perf_models) <- all_models

# Based on test performance
best_cohort1_perf_models <- c(ov_results_cBoost[ov_results_cBoost$ci_coh1==max(ov_results_cBoost$ci_coh1), c("dataset")], 
                            ov_results_coxPas[ov_results_coxPas$ci_coh1==max(ov_results_coxPas$ci_coh1), c("dataset")],
                            ov_results_coxph[ov_results_coxph$ci_coh1==max(ov_results_coxph$ci_coh1), c("dataset")],
                            ov_results_DeepSurv[ov_results_DeepSurv$ci_coh1==max(ov_results_DeepSurv$ci_coh1), c("dataset")],
                            ov_results_prio[ov_results_prio$ci_coh1==max(ov_results_prio$ci_coh1), c("dataset")],
                            ov_results_rsf[ov_results_rsf$ci_coh1==max(ov_results_rsf$ci_coh1), c("dataset")])
names(best_cohort1_perf_models) <- all_models


best_cohort2_perf_models <- c(ov_results_cBoost[ov_results_cBoost$ci_coh2==max(ov_results_cBoost$ci_coh2), c("dataset")], 
                            ov_results_coxPas[ov_results_coxPas$ci_coh2==max(ov_results_coxPas$ci_coh2), c("dataset")],
                            ov_results_coxph[ov_results_coxph$ci_coh2==max(ov_results_coxph$ci_coh2), c("dataset")],
                            ov_results_DeepSurv[ov_results_DeepSurv$ci_coh2==max(ov_results_DeepSurv$ci_coh2), c("dataset")],
                            ov_results_prio[ov_results_prio$ci_coh2==max(ov_results_prio$ci_coh2), c("dataset")],
                            ov_results_rsf[ov_results_rsf$ci_coh2==max(ov_results_rsf$ci_coh2), c("dataset")])
names(best_cohort2_perf_models) <- all_models


## Exprs Based Models Only
best_training_perf_models_exprs <-  c(ov_results_cBoost_exprs_models[ov_results_cBoost_exprs_models$mean==
                                                                       max(ov_results_cBoost_exprs_models$mean), c("dataset")], 
                                       ov_results_coxph_exprs_models[ov_results_coxph_exprs_models$mean==
                                                                       max(ov_results_coxph_exprs_models$mean), c("dataset")],
                            ov_results_DeepSurv_exprs_models[ov_results_DeepSurv_exprs_models$mean==
                                                               max(ov_results_DeepSurv_exprs_models$mean), c("dataset")],
                            ov_results_prio_exprs_models[ov_results_prio_exprs_models$mean==
                                                           max(ov_results_prio_exprs_models$mean), c("dataset")],
                                        ov_results_rsf_exprs_models[ov_results_rsf_exprs_models$mean==
                                                                      max(ov_results_rsf_exprs_models$mean), c("dataset")])
names(best_training_perf_models) <- models_expr_based_only

# Based on test performance
best_cohort1_perf_models_exprs_based <- c(ov_results_cBoost_exprs_models[ov_results_cBoost_exprs_models$ci_coh1==max(ov_results_cBoost_exprs_models$ci_coh1), c("dataset")],
ov_results_coxph_exprs_models[ov_results_coxph_exprs_models$ci_coh1==max(ov_results_coxph_exprs_models$ci_coh1), c("dataset")],
ov_results_DeepSurv_exprs_models[ov_results_DeepSurv_exprs_models$ci_coh1==max(ov_results_DeepSurv_exprs_models$ci_coh1), c("dataset")],
ov_results_prio_exprs_models[ov_results_prio_exprs_models$ci_coh1==max(ov_results_prio_exprs_models$ci_coh1), c("dataset")],
ov_results_rsf_exprs_models[ov_results_rsf_exprs_models$ci_coh1==max(ov_results_rsf_exprs_models$ci_coh1), c("dataset")])
names(best_cohort1_perf_models_exprs_based) <- models_expr_based_only

best_cohort2_perf_models_exprs_based <- c(ov_results_cBoost_exprs_models[ov_results_cBoost_exprs_models$ci_coh2==max(ov_results_cBoost_exprs_models$ci_coh2), c("dataset")],
ov_results_coxph_exprs_models[ov_results_coxph_exprs_models$ci_coh2==max(ov_results_coxph_exprs_models$ci_coh2), c("dataset")],
ov_results_DeepSurv_exprs_models[ov_results_DeepSurv_exprs_models$ci_coh2==max(ov_results_DeepSurv_exprs_models$ci_coh2), c("dataset")],
ov_results_prio_exprs_models[ov_results_prio_exprs_models$ci_coh2==max(ov_results_prio_exprs_models$ci_coh2), c("dataset")],
ov_results_rsf_exprs_models[ov_results_rsf_exprs_models$ci_coh2==max(ov_results_rsf_exprs_models$ci_coh2), c("dataset")])
names(best_cohort2_perf_models_exprs_based) <- models_expr_based_only
```

```{r Create Best Performance Vectors based on previous chunk models}
## All Models
# Based on training performance
test_results_cohort1 <- c(ov_results_cBoost$ci_coh1[which(ov_results_cBoost$mean==max(ov_results_cBoost$mean))],
                          ov_results_coxPas$ci_coh1[which(ov_results_coxPas$mean==max(ov_results_coxPas$mean))],
                          ov_results_coxph$ci_coh1[which(ov_results_coxph$mean==max(ov_results_coxph$mean))],
                          ov_results_DeepSurv$ci_coh1[which(ov_results_DeepSurv$mean==max(ov_results_DeepSurv$mean))],
                          ov_results_prio$ci_coh1[which(ov_results_prio$mean==max(ov_results_prio$mean))],
                          ov_results_rsf$ci_coh1[which(ov_results_rsf$mean==max(ov_results_rsf$mean))])
names(test_results_cohort1) <- all_models


test_results_cohort2 <- c(ov_results_cBoost$ci_coh2[which(ov_results_cBoost$mean==max(ov_results_cBoost$mean))],
                          ov_results_coxPas$ci_coh2[which(ov_results_coxPas$mean==max(ov_results_coxPas$mean))],
                          ov_results_coxph$ci_coh2[which(ov_results_coxph$mean==max(ov_results_coxph$mean))],
                          ov_results_DeepSurv$ci_coh2[which(ov_results_DeepSurv$mean==max(ov_results_DeepSurv$mean))],
                          ov_results_prio$ci_coh2[which(ov_results_prio$mean==max(ov_results_prio$mean))],
                          ov_results_rsf$ci_coh2[which(ov_results_rsf$mean==max(ov_results_rsf$mean))])
names(test_results_cohort2) <- all_models

# Based on test performance
test_results_cohort1_based_on_test <- c(max(ov_results_cBoost$ci_coh1), max(ov_results_coxPas$ci_coh1), max(ov_results_coxph$ci_coh1), max(ov_results_DeepSurv$ci_coh1), max(ov_results_prio$ci_coh1), max(ov_results_rsf$ci_coh1))
names(test_results_cohort1_based_on_test) <- all_models

test_results_cohort2_based_on_test <- c(max(ov_results_cBoost$ci_coh2), max(ov_results_coxPas$ci_coh2), max(ov_results_coxph$ci_coh2), max(ov_results_DeepSurv$ci_coh2), max(ov_results_prio$ci_coh2), max(ov_results_rsf$ci_coh2))
names(test_results_cohort2_based_on_test) <- all_models


## Exprs Only Models
# Based on training performance
test_results_cohort1_exprs_only <- c(ov_results_cBoost_exprs_models$ci_coh1[which(ov_results_cBoost_exprs_models$mean==max(ov_results_cBoost_exprs_models$mean))],
                                     ov_results_coxph_exprs_models$ci_coh1[which(ov_results_coxph_exprs_models$mean==max(ov_results_coxph_exprs_models$mean))],
                                     ov_results_DeepSurv_exprs_models$ci_coh1[which(ov_results_DeepSurv_exprs_models$mean==max(ov_results_DeepSurv_exprs_models$mean))],
                                     ov_results_prio_exprs_models$ci_coh1[which(ov_results_prio_exprs_models$mean==max(ov_results_prio_exprs_models$mean))],
                                     ov_results_rsf_exprs_models$ci_coh1[which(ov_results_rsf_exprs_models$mean==max(ov_results_rsf_exprs_models$mean))])
names(test_results_cohort1_exprs_only) <- models_expr_based_only


test_results_cohort2_exprs_only <- c(ov_results_cBoost_exprs_models$ci_coh2[which(ov_results_cBoost_exprs_models$mean==max(ov_results_cBoost_exprs_models$mean))],
                                     ov_results_coxph_exprs_models$ci_coh2[which(ov_results_coxph_exprs_models$mean==max(ov_results_coxph_exprs_models$mean))],
                                     ov_results_DeepSurv_exprs_models$ci_coh2[which(ov_results_DeepSurv_exprs_models$mean==max(ov_results_DeepSurv_exprs_models$mean))],
                                     ov_results_prio_exprs_models$ci_coh2[which(ov_results_prio_exprs_models$mean==max(ov_results_prio_exprs_models$mean))],
                                     ov_results_rsf_exprs_models$ci_coh2[which(ov_results_rsf_exprs_models$mean==max(ov_results_rsf_exprs_models$mean))])
names(test_results_cohort2_exprs_only) <- models_expr_based_only


# Based on test performance
test_results_cohort1_based_on_test_exprs_only <- c(max(ov_results_cBoost_exprs_models$ci_coh1),  max(ov_results_coxph_exprs_models$ci_coh1), max(ov_results_DeepSurv_exprs_models$ci_coh1), max(ov_results_prio_exprs_models$ci_coh1), max(ov_results_rsf_exprs_models$ci_coh1))
names(test_results_cohort1_based_on_test_exprs_only) <- models_expr_based_only

test_results_cohort2_based_on_test_exprs_only <- c(max(ov_results_cBoost_exprs_models$ci_coh2),  max(ov_results_coxph_exprs_models$ci_coh2), max(ov_results_DeepSurv_exprs_models$ci_coh2), max(ov_results_prio_exprs_models$ci_coh2), max(ov_results_rsf_exprs_models$ci_coh2))
names(test_results_cohort2_based_on_test_exprs_only) <- models_expr_based_only

```

```{r Create Final Data Sets for Plotting}
# Results both cohorts based on training
best_test_results_both_cohorts_train <- data.frame(
  Model = rep(all_models, each = 2), 
  ci = as.vector(rbind(test_results_cohort1, test_results_cohort2)),  
  Cohort = rep(c("Cohort 10", "Cohort11"), times = length(all_models)) 
)

# Results both cohorts based on test
best_test_results_both_cohorts_test <- data.frame(
  Model = rep(all_models, each = 2), 
  ci = as.vector(rbind(test_results_cohort1_based_on_test, test_results_cohort2_based_on_test)),  
  Cohort = rep(c("Cohort 10", "Cohort11"), times = length(all_models)) 
)
# Results both cohorts based on train exprs only
best_test_results_both_cohorts_exprs_only_train <- data.frame(
  Model = rep(models_expr_based_only, each = 2), 
  ci = as.vector(rbind(test_results_cohort1_exprs_only, test_results_cohort2_exprs_only)),  
  Cohort = rep(c("Cohort 10", "Cohort11"), times = length(models_expr_based_only)) 
)
# Results both cohorts based on test exprs only
best_test_results_both_cohorts_exprs_only_test <- data.frame(
  Model = rep(models_expr_based_only, each = 2), 
  ci = as.vector(rbind(test_results_cohort1_based_on_test_exprs_only, test_results_cohort2_based_on_test_exprs_only)),  
  Cohort = rep(c("Cohort 10", "Cohort11"), times = length(models_expr_based_only)) 
)
```

```{r create reference lines}
# Function for adding averages
add_average_rows <- function(data) {
  result <- data.frame()
  for (i in seq(1, nrow(data), by = 2)) {
    result <- rbind(result, data[i, ], data[i + 1, ])
    
    avg_row <- data.frame(
      Model = data$Model[i],
      ci = mean(c(data$ci[i], data$ci[i + 1])),
      Cohort = "Average"
    )
    result <- rbind(result, avg_row)
  }
  return(result)
}

# Results both cohorts train
best_test_results_both_cohorts_train_with_avg <- add_average_rows(best_test_results_both_cohorts_train)

# Results both cohorts test
best_test_results_both_cohorts_test_with_avg <- add_average_rows(best_test_results_both_cohorts_test)

# Results both cohorts train exprs only
best_test_results_both_cohorts_exprs_only_train_with_avg <- add_average_rows(best_test_results_both_cohorts_exprs_only_train)

# Results both cohorts test exprs only
best_test_results_both_cohorts_test_exprs_only_with_avg <- add_average_rows(best_test_results_both_cohorts_test)
```

```{r create reference lines}
#average of the ffpe score on cohorts 1-9 (manually added)
mean_ffpe_score <- 0.701
weighted_mean_ffpe_score <- 0.698
best_training_means <- mean(max(ov_results_cBoost$mean), max(ov_results_coxPas$mean), max(ov_results_coxph$mean, max(ov_results_DeepSurv$mean), max(ov_results_rsf$mean), max(ov_results_prio$mean)))
#mean of all the tst performances of all models
test_mean_all_models <- mean(c(ov_results_cBoost$ci_coh1, ov_results_cBoost$ci_coh2, 
                         ov_results_coxph$ci_coh1, ov_results_coxph$ci_coh2, 
                         ov_results_DeepSurv$ci_coh1, ov_results_DeepSurv$ci_coh2, 
                         ov_results_rsf$ci_coh1, ov_results_rsf$ci_coh2, 
                         ov_results_coxPas$ci_coh1, ov_results_coxPas$ci_coh2, 
                         ov_results_prio$ci_coh1, ov_results_prio$ci_coh2))
# mean of all the training performances of all models
train_mean_all_models <- mean(c(ov_results_cBoost$mean,
                         ov_results_coxph$mean,
                         ov_results_DeepSurv$mean,
                         ov_results_rsf$mean,
                         ov_results_coxPas$mean,
                         ov_results_prio$mean))
#mean of total of 12 best test performances on both test cohorts (best models in training)
test_mean_best_models <- mean(c(test_results_cohort1,test_results_cohort2))


```


```{r Create the Plots}
# Train based best models with mean c-index of ffpe
fp1 <- ggplot(best_test_results_both_cohorts_train_with_avg, aes(y = Model, x = ci, group = Cohort)) +
  
  geom_segment(aes(
    x = ci,
    xend = mean_ffpe_score,
    y = Model,
    yend = Model
  ),
  linetype = "solid", 
  color = "gray") +
  
    # Benchmark
  geom_vline(xintercept = mean_ffpe_score, color = "blue") +
  
  geom_point(aes(color = Cohort), size = 2) +
  
  scale_color_manual(values = c("Cohort 10" = "turquoise", "Cohort11" = "#0c4252", "Average" = "orange")) +
  
  scale_x_continuous(
    limits = c(0.6, 0.85),             
    breaks = seq(0.60, 0.85, 0.05),   
    labels = scales::label_number(accuracy = 0.001) 
  ) +
  
    
  labs(
    title = "Performances of Best Models (Training Based) vs. ProstaTrend-ffpe Score Benchmark",
    x = "C-Index",
    y = "Model",
    color = "Cohort"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0, size = 12, face = "bold"),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


# Train based best models with all models train performance reference 
fp2 <- ggplot(best_test_results_both_cohorts_train_with_avg, aes(y = Model, x = ci, group = Cohort)) +
  
    # Benchmark
  geom_segment(aes(
    x = ci,
    xend = train_mean_all_models,  
    y = Model,
    yend = Model
  ),
  linetype = "solid", 
  color = "gray") +
  
    # Benchmark
  geom_vline(xintercept = train_mean_all_models, color = "blue") +
  
  geom_point(aes(color = Cohort), size = 2) +
  
  scale_color_manual(values = c("Cohort 10" = "turquoise", "Cohort11" = "#0c4252", "Average" = "orange")) +
  
  scale_x_continuous(
    limits = c(0.6, 0.85),             
    breaks = seq(0.60, 0.85, 0.05),   
    labels = scales::label_number(accuracy = 0.001) 
  ) +
  
  labs(
    title = "Performances of Best Models (Training Based) vs. All Models Training Benchmark",
    x = "C-Index",
    y = "Model",
    color = "Cohort"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0, size = 12, face = "bold"),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

# Train based best models with their avrg train performance reference 
fp3 <- ggplot(best_test_results_both_cohorts_train_with_avg, aes(y = Model, x = ci, group = Cohort)) +
  
    # Benchmark
  geom_segment(aes(
    x = ci,
    xend = best_training_means,  
    y = Model,
    yend = Model
  ),
  linetype = "solid", 
  color = "gray") +
  
    # Benchmark
  geom_vline(xintercept = best_training_means, color = "blue") +
  
  geom_point(aes(color = Cohort), size = 2) +
  
  scale_color_manual(values = c("Cohort 10" = "turquoise", "Cohort11" = "#0c4252", "Average" = "orange")) +
  
  scale_x_continuous(
    limits = c(0.6, 0.85),             
    breaks = seq(0.60, 0.85, 0.05),   
    labels = scales::label_number(accuracy = 0.001) 
  ) +
  
  labs(
    title = "Performances of Best Models (Nest. Res. Based) vs. Best Models Nest. Res. Benchmark",
    x = "C-Index",
    y = "Model",
    color = "Cohort"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0, size = 12, face = "bold"),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

# Train based best models with all models test performance reference 
fp4 <-ggplot(best_test_results_both_cohorts_train_with_avg, aes(y = Model, x = ci, group = Cohort)) +
  
  geom_segment(aes(
    x = ci,
    xend = test_mean_all_models, 
    y = Model,
    yend = Model
  ),
  linetype = "solid", 
  color = "gray") +
  
    # Benchmark
  geom_vline(xintercept = test_mean_all_models, color = "blue") +
  
  geom_point(aes(color = Cohort), size = 2) +
  
  scale_color_manual(values = c("Cohort 10" = "turquoise", "Cohort11" = "#0c4252", "Average" = "orange")) +
  
  scale_x_continuous(
    limits = c(0.6, 0.85),             
    breaks = seq(0.60, 0.85, 0.05),   
    labels = scales::label_number(accuracy = 0.001) 
  ) +
  
  labs(
    title = "Performances of Best Models (Training Based) vs. All Models Test Benchmark",
    x = "C-Index",
    y = "Model",
    color = "Cohort"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0, size = 12, face = "bold"),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


# Test based best models with average of them as reference
fp5 <-ggplot(best_test_results_both_cohorts_test_with_avg, aes(y = Model, x = ci, group = Cohort)) +
  
  geom_segment(aes(
    x = ci,
    xend = test_mean_best_models, 
    y = Model,
    yend = Model
  ),
  linetype = "solid", 
  color = "gray") +
  
  # Benchmark
  geom_vline(xintercept = test_mean_best_models, color = "blue") +
  
  geom_point(aes(color = Cohort), size = 2) +
  
  scale_color_manual(values = c("Cohort 10" = "turquoise", "Cohort11" = "#0c4252", "Average" = "orange")) +
  
  scale_x_continuous(
    limits = c(0.6, 0.85),             
    breaks = seq(0.60, 0.85, 0.05),   
    labels = scales::label_number(accuracy = 0.001) 
  ) +
  
  labs(
    title = "Performances of Best Models (Test Based) vs. Average of all Dots Benchmark",
    x = "C-Index",
    y = "Model",
    color = "Cohort"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0, size = 12, face = "bold"),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


# Test based best models with average of  all models performances on test date
fp6 <-ggplot(best_test_results_both_cohorts_test_with_avg, aes(y = Model, x = ci, group = Cohort)) +
  
  geom_segment(aes(
    x = ci,
    xend = test_mean_all_models,  
    y = Model,
    yend = Model
  ),
  linetype = "solid", 
  color = "gray") +
  
  # Benchmark
  geom_vline(xintercept = test_mean_all_models, color = "blue") +
  
  geom_point(aes(color = Cohort), size = 2) +
  
  scale_color_manual(values = c("Cohort 10" = "turquoise", "Cohort11" = "#0c4252", "Average" = "orange")) +
  
  scale_x_continuous(
    limits = c(0.6, 0.85),             
    breaks = seq(0.60, 0.85, 0.05),   
    labels = scales::label_number(accuracy = 0.001) 
  ) +
  
  labs(
    title = "Performances of Best Models (Test Based) vs. All Models Test Benchmark",
    x = "C-Index",
    y = "Model",
    color = "Cohort"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0, size = 12, face = "bold"),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


# Train based best models (exprs only) with mean ffpe score as reference
fp7 <-ggplot(best_test_results_both_cohorts_exprs_only_train_with_avg, aes(y = Model, x = ci, group = Cohort)) +
  
  geom_segment(aes(
    x = ci,
    xend = mean_ffpe_score, 
    y = Model,
    yend = Model
  ),
  linetype = "solid", 
  color = "gray") +
    # Benchmark
  geom_vline(xintercept = mean_ffpe_score, color = "blue") +
  
  geom_point(aes(color = Cohort), size = 2) +
  
  scale_color_manual(values = c("Cohort 10" = "turquoise", "Cohort11" = "#0c4252", "Average" = "orange")) +
  
  scale_x_continuous(
    limits = c(0.6, 0.85),             
    breaks = seq(0.60, 0.85, 0.05),   
    labels = scales::label_number(accuracy = 0.001) 
  ) +

  labs(
    title = "Performances of Best Exprs Based Models (Training Based) vs. ProstaTrend-ffpe Score Benchmark",
    x = "C-Index",
    y = "Model",
    color = "Cohort"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0, size = 12, face = "bold"),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )


```
```{r comparing mean performance of exprs based models vs pData vs both}
test_mean_all_models <- mean(c(ov_results_cBoost$ci_coh1, ov_results_cBoost$ci_coh2, 
                         ov_results_coxph$ci_coh1, ov_results_coxph$ci_coh2, 
                         ov_results_DeepSurv$ci_coh1, ov_results_DeepSurv$ci_coh2, 
                         ov_results_rsf$ci_coh1, ov_results_rsf$ci_coh2, 
                         ov_results_coxPas$ci_coh1, ov_results_coxPas$ci_coh2, 
                         ov_results_prio$ci_coh1, ov_results_prio$ci_coh2))
mean_pData_results <- mean(c(ov_results_cBoost[7,]$ci_coh1,  
                         ov_results_coxph[7,]$ci_coh1, 
                         ov_results_DeepSurv[7,]$ci_coh1, 
                         ov_results_rsf[7,]$ci_coh1))
mean_exprs_results <- mean(c(ov_results_cBoost[c(1, 3, 5),]$ci_coh1,  
                         ov_results_coxph[c(1, 3, 5),]$ci_coh1, 
                         ov_results_DeepSurv[c(1, 3, 5),]$ci_coh1, 
                         ov_results_rsf[c(1, 3, 5),]$ci_coh1))
mean_exprs_pData_results <- mean(c(ov_results_cBoost[c(2, 4, 6),]$ci_coh1,  
                         ov_results_coxph[c(2, 4, 6),]$ci_coh1, 
                         ov_results_DeepSurv[c(2, 4, 6),]$ci_coh1, 
                         ov_results_rsf[c(2, 4, 6),]$ci_coh1))



```
