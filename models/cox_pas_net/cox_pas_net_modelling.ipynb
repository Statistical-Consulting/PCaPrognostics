{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAkYtXXlt943"
      },
      "source": [
        "Link to Google Colab NB: https://colab.research.google.com/drive/1Oxo6fWugdue3QxtJ2d5DWYPVC9tRa6Pc?usp=sharing\n",
        "\n",
        "How to use this code (in Google Colab):\n",
        "1.   Upload data sets to content pane. To run the code wo. modifications the data sets should be called:\n",
        "*   exprs_intersect.csv for gene data\n",
        "*   merged_imputed_pData.csv for clinical data\n",
        "*   pathway_mask.csv for pathway data\n",
        "\n",
        "2.   Adapt model parameters and modelling process parameters in MODEL_CONFIG:  \n",
        "- To perform nested resampling set 'do_nested_resampling' in MODEL_CONFIG to True\n",
        "- To train final model set 'refit' in MODEL_CONFIG to True\n",
        "- Adapt model hyperparameters to your liking\n",
        "3.   Run the Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijlIpVH4KVlM",
        "outputId": "55743a9e-1b05-41f5-d6c1-e0f29e23561d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.11/dist-packages (0.30.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.7.0)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.11/dist-packages (from lifelines) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.1.1)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.17.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
            "Requirement already satisfied: scikit-survival in /usr/local/lib/python3.11/dist-packages (0.23.1)\n",
            "Requirement already satisfied: ecos in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.0.14)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.4.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.26.4)\n",
            "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (0.6.7.post3)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.13.1)\n",
            "Collecting scikit-learn<1.6,>=1.4.0 (from scikit-survival)\n",
            "  Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.11/dist-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (0.1.7.post5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6,>=1.4.0->scikit-survival) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->scikit-survival) (1.17.0)\n",
            "Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.5.2\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Using cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n",
            "Using cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.2\n",
            "    Uninstalling scikit-learn-1.5.2:\n",
            "      Successfully uninstalled scikit-learn-1.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-survival 0.23.1 requires scikit-learn<1.6,>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.2.2\n"
          ]
        }
      ],
      "source": [
        "# Chunk 1\n",
        "!pip install lifelines\n",
        "!pip install scikit-survival\n",
        "!pip install scikit-learn==1.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "306tz2SuGR87"
      },
      "outputs": [],
      "source": [
        "# Chunk 2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneGroupOut, KFold, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.base import clone\n",
        "from itertools import product\n",
        "import logging\n",
        "#from utils.evaluation import cindex_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def _get_survival_subset(y, indices):\n",
        "    \"\"\"Extract survival data subset while preserving structure\"\"\"\n",
        "    subset = np.empty(len(indices), dtype=y.dtype)\n",
        "    event_field = 'status' if 'status' in y.dtype.names else 'event'\n",
        "    subset[event_field] = y[event_field][indices]\n",
        "    subset['time'] = y['time'][indices]\n",
        "    return subset\n",
        "\n",
        "def _aggregate_results(results):\n",
        "    \"\"\"Aggregates nested CV results.\"\"\"\n",
        "    scores = [res['test_score'] for res in results]\n",
        "    mean_score = np.mean(scores)\n",
        "    std_score = np.std(scores)\n",
        "\n",
        "    logger.info(f\"Aggregated results:\")\n",
        "    logger.info(f\"Mean score: {mean_score:.3f} Â± {std_score:.3f}\")\n",
        "    logger.info(f\"Individual scores: {scores}\")\n",
        "\n",
        "    return {\n",
        "        'mean_score': mean_score,\n",
        "        'std_score': std_score,\n",
        "        'fold_results': results\n",
        "    }\n",
        "\n",
        "def nested_resampling(estimator, X, y, groups, param_grid, monitor = None, ss = GridSearchCV, outer_cv = LeaveOneGroupOut(), inner_cv = LeaveOneGroupOut(), scoring = None):\n",
        "    logger.info(\"Starting nested resampling...\")\n",
        "    logger.info(f\"Data shape: X={X.shape}, groups={len(np.unique(groups))} unique\")\n",
        "\n",
        "    outer_results = []\n",
        "\n",
        "    for i, (train_idx, test_idx) in enumerate(outer_cv.split(X, y, groups)):\n",
        "        logger.info(f\"\\nOuter fold {i+1}\")\n",
        "\n",
        "        X_train = X.iloc[train_idx]\n",
        "        X_test = X.iloc[test_idx]\n",
        "        y_train = _get_survival_subset(y, train_idx)\n",
        "        y_test = _get_survival_subset(y, test_idx)\n",
        "        train_groups = groups[train_idx] if groups is not None else None\n",
        "\n",
        "        test_cohort = groups[test_idx][0] if groups is not None else None\n",
        "        logger.info(f\"Test cohort: {test_cohort}\")\n",
        "\n",
        "        inner_gcv = ss(estimator, param_grid, cv = inner_cv, refit = True, n_jobs=4, verbose = 2)\n",
        "        if monitor is not None:\n",
        "            inner_results = inner_gcv.fit(X_train, y_train, groups = train_groups, model__monitor = monitor)\n",
        "            logger.info(\n",
        "                f\"number of iterations early stopping: {inner_results.best_estimator_.named_steps['model'].n_estimators_}\")\n",
        "\n",
        "        else:\n",
        "            inner_results = inner_gcv.fit(X_train, y_train, groups = train_groups)\n",
        "\n",
        "        inner_cv_results = inner_results.cv_results_\n",
        "        inner_best_params = inner_results.best_params_\n",
        "\n",
        "        outer_model = inner_results.best_estimator_\n",
        "        test_score = outer_model.score(X_test, y_test)\n",
        "\n",
        "        logger.info(f\"Best parameters: {inner_best_params}\")\n",
        "        logger.info(f\"Test score: {test_score:.3f}\")\n",
        "\n",
        "        outer_results.append({\n",
        "            'test_cohort': test_cohort,\n",
        "            'test_score': test_score,\n",
        "            'best_params': inner_best_params,\n",
        "            'inner_cv_results': inner_cv_results\n",
        "        })\n",
        "\n",
        "    return _aggregate_results(outer_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Uw-x2WEoGW7t"
      },
      "outputs": [],
      "source": [
        "# Chunk 3\n",
        "\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from lifelines.utils import concordance_index\n",
        "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
        "import logging\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "from scipy.interpolate import interp1d\n",
        "dtype = torch.FloatTensor\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\"\"\"\n",
        "The following code is based on the implementation from https://github.com/DataX-JieHao/Cox-PASNet\n",
        "\"\"\"\n",
        "\n",
        "def dropout_mask(n_node, drop_p):\n",
        "\t'''Construct a binary matrix to randomly drop nodes in a layer.\n",
        "\tInput:\n",
        "\t\tn_node: number of nodes in the layer.\n",
        "\t\tdrop_p: the probability that a node is to be dropped.\n",
        "\tOutput:\n",
        "\t\tmask: a binary matrix, where 1 --> keep the node; 0 --> drop the node.\n",
        "\t'''\n",
        "\tkeep_p = 1.0 - drop_p\n",
        "\tmask = torch.Tensor(np.random.binomial(1, keep_p, size=n_node))\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tmask = mask.cuda()\n",
        "\t###\n",
        "\treturn mask\n",
        "\n",
        "def s_mask(sparse_level, param_matrix, nonzero_param_1D, dtype):\n",
        "\t'''Construct a binary matrix w.r.t. a sparsity level of weights between two consecutive layers\n",
        "\tInput:\n",
        "\t\tsparse_level: a percentage value in [0, 100) represents the proportion of weights in a sub-network to be dropped.\n",
        "\t\tparam_matrix: a weight matrix for entrie network.\n",
        "\t\tnonzero_param_1D: 1D of non-zero 'param_matrix' (which is the weights selected from a sub-network).\n",
        "\t\tdtype: define the data type of tensor (i.e. dtype=torch.FloatTensor).\n",
        "\tOutput:\n",
        "\t\tparam_mask: a binary matrix, where 1 --> keep the node; 0 --> drop the node.\n",
        "\t'''\n",
        "\t###take the absolute values of param_1D\n",
        "\tnon_neg_param_1D = torch.abs(nonzero_param_1D)\n",
        "\t###obtain the number of params\n",
        "\tnum_param = nonzero_param_1D.size(0)\n",
        "\t###obtain the kth number based on sparse_level\n",
        "\ttop_k = math.ceil(num_param*(100-sparse_level)*0.01)\n",
        "\t###obtain the k largest params\n",
        "\tsorted_non_neg_param_1D, indices = torch.topk(non_neg_param_1D, top_k)\n",
        "\tparam_mask = torch.abs(param_matrix) > sorted_non_neg_param_1D.min()\n",
        "\tparam_mask = param_mask.type(dtype)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tparam_mask = param_mask.cuda()\n",
        "\t###\n",
        "\treturn param_mask\n",
        "\n",
        "def R_set(x):\n",
        "\t'''Create an indicator matrix of risk sets, where T_j >= T_i.\n",
        "\tNote that the input data have been sorted in descending order.\n",
        "\tInput:\n",
        "\t\tx: a PyTorch tensor that the number of rows is equal to the number of samples.\n",
        "\tOutput:\n",
        "\t\tindicator_matrix: an indicator matrix (which is a lower traiangular portions of matrix).\n",
        "\t'''\n",
        "\tn_sample = x.size(0)\n",
        "\tmatrix_ones = torch.ones(n_sample, n_sample)\n",
        "\tindicator_matrix = torch.tril(matrix_ones)\n",
        "\n",
        "\treturn(indicator_matrix)\n",
        "\n",
        "\n",
        "def neg_par_log_likelihood(pred, ytime, yevent):\n",
        "\t'''Calculate the average Cox negative partial log-likelihood.\n",
        "\tNote that this function requires the input data have been sorted in descending order.\n",
        "\tInput:\n",
        "\t\tpred: linear predictors from trained model.\n",
        "\t\tytime: true survival time from load_data().\n",
        "\t\tyevent: true censoring status from load_data().\n",
        "\tOutput:\n",
        "\t\tcost: the cost that is to be minimized.\n",
        "\t'''\n",
        "\tn_observed = yevent.sum(0)\n",
        "\tytime_indicator = R_set(ytime)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tytime_indicator = ytime_indicator.cuda()\n",
        "\t###\n",
        "\trisk_set_sum = ytime_indicator.mm(torch.exp(pred))\n",
        "\tdiff = pred - torch.log(risk_set_sum)\n",
        "\tsum_diff_in_observed = torch.transpose(diff, 0, 1).mm(yevent)\n",
        "\tcost = (- (sum_diff_in_observed / n_observed)).reshape((-1,))\n",
        "\n",
        "\treturn(cost)\n",
        "\n",
        "\n",
        "def c_index(pred, ytime, yevent):\n",
        "\t'''Calculate concordance index to evaluate models.\n",
        "\tInput:\n",
        "\t\tpred: linear predictors from trained model.\n",
        "\t\tytime: true survival time from load_data().\n",
        "\t\tyevent: true censoring status from load_data().\n",
        "\tOutput:\n",
        "\t\tconcordance_index: c-index (between 0 and 1).\n",
        "\t'''\n",
        "\tn_sample = len(ytime)\n",
        "\tytime_indicator = R_set(ytime)\n",
        "\tytime_matrix = ytime_indicator - torch.diag(torch.diag(ytime_indicator))\n",
        "\t###T_i is uncensored\n",
        "\tcensor_idx = (yevent == 0).nonzero()\n",
        "\tzeros = torch.zeros(n_sample)\n",
        "\tytime_matrix[censor_idx, :] = zeros\n",
        "\t###1 if pred_i < pred_j; 0.5 if pred_i = pred_j\n",
        "\tpred_matrix = torch.zeros_like(ytime_matrix)\n",
        "\tfor j in range(n_sample):\n",
        "\t\tfor i in range(n_sample):\n",
        "\t\t\tif pred[i] < pred[j]:\n",
        "\t\t\t\tpred_matrix[j, i]  = 1\n",
        "\t\t\telif pred[i] == pred[j]:\n",
        "\t\t\t\tpred_matrix[j, i] = 0.5\n",
        "\n",
        "\tconcord_matrix = pred_matrix.mul(ytime_matrix)\n",
        "\t###numerator\n",
        "\tconcord = torch.sum(concord_matrix)\n",
        "\t###denominator\n",
        "\tepsilon = torch.sum(ytime_matrix)\n",
        "\t###c-index = numerator/denominator\n",
        "\tconcordance_index = torch.div(concord, epsilon)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tconcordance_index = concordance_index.cuda()\n",
        "\t###\n",
        "\treturn(concordance_index)\n",
        "\n",
        "\n",
        "class Cox_PASNet(nn.Module):\n",
        "\tdef __init__(self, In_Nodes, Pathway_Nodes, Hidden_Nodes, Out_Nodes, Pathway_Mask, n_clin):\n",
        "\t\tsuper(Cox_PASNet, self).__init__()\n",
        "\t\tself.tanh = nn.Tanh()\n",
        "\t\tself.pathway_mask = Pathway_Mask\n",
        "\t\t###gene layer --> pathway layer\n",
        "\t\tself.sc1 = nn.Linear(In_Nodes, Pathway_Nodes)\n",
        "\t\t###pathway layer --> hidden layer\n",
        "\t\tself.sc2 = nn.Linear(Pathway_Nodes, Hidden_Nodes)\n",
        "\t\t###hidden layer --> hidden layer 2\n",
        "\t\tself.sc3 = nn.Linear(Hidden_Nodes, Out_Nodes, bias=False)\n",
        "\t\t###hidden layer 2 + age --> Cox layer\n",
        "\t\tself.sc4 = nn.Linear(Out_Nodes+n_clin, 1, bias = False)\n",
        "\t\tself.sc4.weight.data.uniform_(-0.001, 0.001)\n",
        "\t\t###randomly select a small sub-network\n",
        "\t\tself.do_m1 = torch.ones(Pathway_Nodes)\n",
        "\t\tself.do_m2 = torch.ones(Hidden_Nodes)\n",
        "\t\t###if gpu is being used\n",
        "\t\tif torch.cuda.is_available():\n",
        "\t\t\tself.do_m1 = self.do_m1.cuda()\n",
        "\t\t\tself.do_m2 = self.do_m2.cuda()\n",
        "\n",
        "\tdef forward(self, x_1, x_2):\n",
        "\t\t###force the connections between gene layer and pathway layer w.r.t. 'pathway_mask'\n",
        "\t\tself.sc1.weight.data = self.sc1.weight.data.mul(self.pathway_mask)\n",
        "\t\tx_1 = self.tanh(self.sc1(x_1))\n",
        "\t\tif self.training == True: ###construct a small sub-network for training only\n",
        "\t\t\tx_1 = x_1.mul(self.do_m1)\n",
        "\t\tx_1 = self.tanh(self.sc2(x_1))\n",
        "\t\tif self.training == True: ###construct a small sub-network for training only\n",
        "\t\t\tx_1 = x_1.mul(self.do_m2)\n",
        "\t\tx_1 = self.tanh(self.sc3(x_1))\n",
        "\t\t###combine age with hidden layer 2\n",
        "\t\tx_cat = torch.cat((x_1, x_2), 1)\n",
        "\t\tlin_pred = self.sc4(x_cat)\n",
        "\n",
        "\t\treturn lin_pred\n",
        "\n",
        "\n",
        "class Cox_PASNet_Model(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self,\n",
        "                 pathway_mask,\n",
        "                 In_Nodes = None,\n",
        "                 Pathway_Nodes = None,\n",
        "                 Hidden_Nodes = 100,\n",
        "                 Out_Nodes = 10,\n",
        "                 Learning_Rate = 0.01,\n",
        "                 L2 = 0,\n",
        "                 Num_Epochs = 100,\n",
        "                 Dropout_Rate = [0.1, 0.1],\n",
        "                 clin_covs = None,\n",
        "                 device='cuda', random_state=123,\n",
        "                 path = None,\n",
        "                 refit = False):\n",
        "\n",
        "        self.device = device if torch.cuda.is_available() and device == 'cuda' else 'cpu'\n",
        "        self.random_state = random_state\n",
        "        torch.manual_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = None\n",
        "        self.is_fitted_ = False\n",
        "        self.training_history_ = {'train_loss': [], 'val_loss': []}\n",
        "\n",
        "        self.In_Nodes = In_Nodes\n",
        "        self.Pathway_Nodes = Pathway_Nodes\n",
        "        self.Hidden_Nodes = Hidden_Nodes\n",
        "        self.Out_Nodes = Out_Nodes\n",
        "        self.Learning_Rate = Learning_Rate\n",
        "        self.L2 = L2\n",
        "        self.Num_Epochs = Num_Epochs\n",
        "        self.Dropout_Rate = Dropout_Rate\n",
        "        self.clin_covs = clin_covs\n",
        "        self.n_clin = len(self.clin_covs)\n",
        "        self.pathway_mask = pathway_mask\n",
        "        self.refit = refit\n",
        "        self.path = path\n",
        "\n",
        "        self.training_history_ = {'train_loss': [], 'val_loss': []}\n",
        "\n",
        "    def fit(self, X, y, patience = 5):\n",
        "        \"\"\"\n",
        "        Trains the Cox-PASNet model using negative partial log-likelihood as the loss function;\n",
        "        Adapted to fit into the scikit-learn interface/API.\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Feature matrix (genomic and clinical data).\n",
        "            y (structured array): Array containing survival time and event status.\n",
        "            patience (int): Number of epochs to wait for improvement before early stopping.\n",
        "\n",
        "        Returns:\n",
        "            self: Fitted instance of Cox_PASNet_Model.\n",
        "        \"\"\"\n",
        "        train_x, train_age, train_ytime, train_yevent, \\\n",
        "        eval_x, eval_age, eval_ytime, eval_yevent = self._prepare_data(X, y, val_split = 0.1)\n",
        "        pathway_mask = self._prepare_pathway(self.pathway_mask, torch.FloatTensor)\n",
        "\n",
        "        self.model = Cox_PASNet(self.In_Nodes, self.Pathway_Nodes, self.Hidden_Nodes, self.Out_Nodes, pathway_mask, self.n_clin)\n",
        "        ###if gpu is being used\n",
        "        if torch.cuda.is_available():\n",
        "            self.model.cuda()\n",
        "        ###\n",
        "        ###optimizer\n",
        "        opt = optim.Adam(self.model.parameters(), lr=self.Learning_Rate, weight_decay = self.L2)\n",
        "\n",
        "        counter = 0\n",
        "        counter = 0\n",
        "        best_val_loss = float('inf')\n",
        "        best_model_state = None\n",
        "        for epoch in range(self.Num_Epochs+1):\n",
        "            self.model.train()\n",
        "            opt.zero_grad() ###reset gradients to zeros\n",
        "            ###Randomize dropout masks\n",
        "            self.model.do_m1 = dropout_mask(self.Pathway_Nodes, self.Dropout_Rate[0])\n",
        "            self.model.do_m2 = dropout_mask(self.Hidden_Nodes, self.Dropout_Rate[1])\n",
        "\n",
        "            pred = self.model(train_x, train_age) ###Forward\n",
        "            loss = neg_par_log_likelihood(pred, train_ytime, train_yevent) ###calculate loss\n",
        "            loss.backward() ###calculate gradients\n",
        "            opt.step() ###update weights and biases\n",
        "\n",
        "            self.model.sc1.weight.data = self.model.sc1.weight.data.mul(self.model.pathway_mask) ###force the connections between gene layer and pathway layer\n",
        "\n",
        "            ###obtain the small sub-network's connections\n",
        "            do_m1_grad = copy.deepcopy(self.model.sc2.weight._grad.data)\n",
        "            do_m2_grad = copy.deepcopy(self.model.sc3.weight._grad.data)\n",
        "            do_m1_grad_mask = torch.where(do_m1_grad == 0, do_m1_grad, torch.ones_like(do_m1_grad))\n",
        "            do_m2_grad_mask = torch.where(do_m2_grad == 0, do_m2_grad, torch.ones_like(do_m2_grad))\n",
        "            ###copy the weights\n",
        "            net_sc2_weight = copy.deepcopy(self.model.sc2.weight.data)\n",
        "            net_sc3_weight = copy.deepcopy(self.model.sc3.weight.data)\n",
        "\n",
        "            ###serializing net\n",
        "            net_state_dict = self.model.state_dict()\n",
        "\n",
        "            ###Sparse Coding\n",
        "            ###make a copy for net, and then optimize sparsity level via copied net\n",
        "            copy_net = copy.deepcopy(self.model)\n",
        "            copy_state_dict = copy_net.state_dict()\n",
        "            for name, param in copy_state_dict.items():\n",
        "                ###omit the param if it is not a weight matrix\n",
        "                if not \"weight\" in name:\n",
        "                    continue\n",
        "                ###omit gene layer\n",
        "                if \"sc1\" in name:\n",
        "                    continue\n",
        "                ###stop sparse coding\n",
        "                if \"sc4\" in name:\n",
        "                    break\n",
        "                ###sparse coding between the current two consecutive layers is in the trained small sub-network\n",
        "                if \"sc2\" in name:\n",
        "                    active_param = net_sc2_weight.mul(do_m1_grad_mask)\n",
        "                if \"sc3\" in name:\n",
        "                    active_param = net_sc3_weight.mul(do_m2_grad_mask)\n",
        "                nonzero_param_1d = active_param[active_param != 0]\n",
        "                if nonzero_param_1d.size(0) == 0: ###stop sparse coding between the current two consecutive layers if there are no valid weights\n",
        "                    break\n",
        "                copy_param_1d = copy.deepcopy(nonzero_param_1d)\n",
        "                ###set up potential sparsity level in [0, 100)\n",
        "                S_set =  torch.arange(100, -1, -1)[1:]\n",
        "                copy_param = copy.deepcopy(active_param)\n",
        "                S_loss = []\n",
        "                for S in S_set:\n",
        "                    param_mask = s_mask(sparse_level = S.item(), param_matrix = copy_param, nonzero_param_1D = copy_param_1d, dtype = dtype)\n",
        "                    transformed_param = copy_param.mul(param_mask)\n",
        "                    copy_state_dict[name].copy_(transformed_param)\n",
        "                    copy_net.train()\n",
        "                    y_tmp = copy_net(train_x, train_age)\n",
        "                    loss_tmp = neg_par_log_likelihood(y_tmp, train_ytime, train_yevent).detach().cpu().numpy()\n",
        "                    S_loss.append(loss_tmp)\n",
        "                ###apply cubic interpolation\n",
        "                S_set = S_set.cpu().numpy() if isinstance(S_set, torch.Tensor) else S_set\n",
        "                S_loss = np.array(S_loss) if isinstance(S_loss, list) else S_loss\n",
        "                interp_S_loss = interp1d(S_set, S_loss, kind='cubic', axis = 0)\n",
        "                interp_S_set = torch.linspace(min(S_set), max(S_set), steps=100)\n",
        "                interp_loss = interp_S_loss(interp_S_set)\n",
        "                optimal_S = interp_S_set[np.argmin(interp_loss)]\n",
        "                optimal_param_mask = s_mask(sparse_level = optimal_S.item(), param_matrix = copy_param, nonzero_param_1D = copy_param_1d, dtype = dtype)\n",
        "                if \"sc2\" in name:\n",
        "                    final_optimal_param_mask = torch.where(do_m1_grad_mask == 0, torch.ones_like(do_m1_grad_mask), optimal_param_mask)\n",
        "                    optimal_transformed_param = net_sc2_weight.mul(final_optimal_param_mask)\n",
        "                if \"sc3\" in name:\n",
        "                    final_optimal_param_mask = torch.where(do_m2_grad_mask == 0, torch.ones_like(do_m2_grad_mask), optimal_param_mask)\n",
        "                    optimal_transformed_param = net_sc3_weight.mul(final_optimal_param_mask)\n",
        "                ###update weights in copied net\n",
        "                copy_state_dict[name].copy_(optimal_transformed_param)\n",
        "                ###update weights in net\n",
        "                net_state_dict[name].copy_(optimal_transformed_param)\n",
        "\n",
        "            self.model.eval()\n",
        "            eval_pred = self.model(eval_x, eval_age)\n",
        "            eval_loss = neg_par_log_likelihood(eval_pred, eval_ytime, eval_yevent).view(1,)\n",
        "\n",
        "            self.training_history_['train_loss'].append(loss)\n",
        "\n",
        "            self.training_history_['val_loss'].append(eval_loss)\n",
        "            print(\"Loss in Eval: \", eval_loss)\n",
        "\n",
        "            if eval_loss < best_val_loss:\n",
        "                best_val_loss = eval_loss\n",
        "                best_model_state = copy.deepcopy(self.model.state_dict())\n",
        "                counter = 0\n",
        "            else:\n",
        "                counter += 1\n",
        "\n",
        "            if counter > patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        if best_model_state is not None:\n",
        "            self.model.load_state_dict(best_model_state)\n",
        "\n",
        "        self.is_fitted_ = True\n",
        "        return self\n",
        "\n",
        "    def _check_early_stopping(self, counter):\n",
        "        if len(self.training_history_['val_loss']) < 2:\n",
        "            return 0.0\n",
        "\n",
        "        if self.training_history_['val_loss'][-1] < self.training_history_['val_loss'][-2]:\n",
        "            counter = 0.0\n",
        "        else:\n",
        "            counter += 1.0\n",
        "        return counter\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict risk scores for given input data;\n",
        "        Adapted to fit into the scikit-learn interface/API.\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Input feature matrix.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Predicted risk scores (flattened tensor).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        pdata = X.loc[:, self.clin_covs].values\n",
        "        pdata =  torch.FloatTensor(pdata).to(self.device)\n",
        "        X = X.drop(self.clin_covs, axis = 1)\n",
        "        intersect_cols = np.intersect1d(self.pathway_mask.columns, X.columns)\n",
        "        X = X.loc[: , intersect_cols].values\n",
        "        X = torch.FloatTensor(X).to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            risk_scores = self.model(X, pdata)\n",
        "        return risk_scores.flatten()\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        Calculates the C-index for the model's predictions.\n",
        "        Adapted to fit into the scikit-learn interface/API.\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Feature matrix.\n",
        "            y (structured array): Survival time and event status.\n",
        "\n",
        "        Returns:\n",
        "            float: C-index.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        preds = self.predict(X)\n",
        "        event_field = 'status' if 'status' in y.dtype.names else 'event'\n",
        "        y_time = torch.FloatTensor(y['time'].copy()).to(self.device)\n",
        "        y_event = np.ascontiguousarray(y[event_field].copy()).astype(np.float32)\n",
        "        y_event = torch.from_numpy(y_event).to(self.device)\n",
        "        return c_index(preds, y_time, y_event).cpu().detach().numpy()\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        return self\n",
        "\n",
        "    def clone(self):\n",
        "        super(self).clone()\n",
        "\n",
        "    def _prepare_data(self, X, y, val_split = 0.1):\n",
        "        \"\"\"\n",
        "        Prepares and splits the data into training and validation sets.\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Feature matrix.\n",
        "            y (structured array): Array containing survival time and event status.\n",
        "            val_split (float): Proportion of data to use for validation.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Tensors for training and validation sets (features, survival times, event indicators).\n",
        "        \"\"\"\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_split, random_state=42)\n",
        "\n",
        "        event_field_train = 'status' if 'status' in y_train.dtype.names else 'event'\n",
        "        y_train = pd.DataFrame(y_train).set_index(X_train.index)\n",
        "\n",
        "        data_train = pd.concat([X_train, y_train], axis = 1, ignore_index=False)\n",
        "        X_train, times_train, events_train, pdata_train = self._sort_data(data_train, event_field_train, 'time', self.clin_covs)\n",
        "\n",
        "        X_tensor_train = torch.FloatTensor(X_train).to(self.device)\n",
        "        time_tensor_train = torch.FloatTensor(times_train).to(self.device)\n",
        "        event_tensor_train = np.ascontiguousarray(events_train).astype(np.float32)\n",
        "        event_tensor_train = torch.from_numpy(event_tensor_train).to(self.device)\n",
        "        pdata_tensor_train = torch.FloatTensor(pdata_train).to(self.device)\n",
        "\n",
        "        event_field_val = 'status' if 'status' in y_val.dtype.names else 'event'\n",
        "        y_val = pd.DataFrame(y_val).set_index(X_val.index)\n",
        "        data_val = pd.concat([X_val, y_val], axis = 1, ignore_index=False)\n",
        "        X_val, times_val, events_val, pdata_val = self._sort_data(data_val, event_field_val, 'time', self.clin_covs)\n",
        "\n",
        "        X_tensor_val = torch.FloatTensor(X_val).to(self.device)\n",
        "        time_tensor_val = torch.FloatTensor(times_val).to(self.device)\n",
        "        event_tensor_val= np.ascontiguousarray(events_val).astype(np.float32)\n",
        "        event_tensor_val = torch.FloatTensor(event_tensor_val).to(self.device)\n",
        "        pdata_tensor_val = torch.FloatTensor(pdata_val).to(self.device)\n",
        "\n",
        "        return X_tensor_train, pdata_tensor_train, time_tensor_train, event_tensor_train, X_tensor_val, pdata_tensor_val, time_tensor_val, event_tensor_val\n",
        "\n",
        "\n",
        "    def _sort_data(self, data, event_field, times_field, clin_vars = None):\n",
        "        \"\"\"\n",
        "        Sorts the gene and clinical data based on survival time in descending order.\n",
        "        (Structure necessary for Cox-PASNet)\n",
        "\n",
        "        Args:\n",
        "            data (pd.DataFrame): Combined gene and clinical data.\n",
        "            event_field (str): Column name for event status.\n",
        "            times_field (str): Column name for survival time.\n",
        "            clin_vars (list): List of clinical covariate names.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Sorted gene data, survival times, event status, and clinical covariates.\n",
        "        \"\"\"\n",
        "\n",
        "        data.sort_values(times_field, ascending = False, inplace = True)\n",
        "        x = data\n",
        "        if clin_vars is not None:\n",
        "            pData = data.loc[:, self.clin_covs].values\n",
        "            x = data.drop(self.clin_covs, axis = 1)\n",
        "        x = x.drop([times_field, event_field], axis = 1)\n",
        "        intersect_cols = np.intersect1d(self.pathway_mask.columns, x.columns)\n",
        "        x = x.loc[: , intersect_cols].values\n",
        "        self.In_Nodes = len(intersect_cols)\n",
        "        ytime = data.loc[:, [times_field]].values\n",
        "        yevent = data.loc[:, [event_field]].values\n",
        "        self.pathway_mask = self.pathway_mask.loc[:, intersect_cols]\n",
        "        self.Pathway_Nodes = self.pathway_mask.shape[0]\n",
        "        return(x, ytime, yevent, pData)\n",
        "\n",
        "\n",
        "    def _prepare_pathway(self, pathway_mask, dtype):\n",
        "        \"\"\"\n",
        "        Converts the pathway mask to a PyTorch tensor.\n",
        "\n",
        "        Args:\n",
        "            pathway_mask (pd.DataFrame): Bi-adjacency matrix for pathways.\n",
        "            dtype (torch.dtype): Data type for the tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Tensor representation of the pathway mask.\n",
        "        \"\"\"\n",
        "        pathway_mask = self.pathway_mask.values\n",
        "        PATHWAY_MASK = torch.from_numpy(pathway_mask).type(dtype)\n",
        "        ###if gpu is being used\n",
        "        if torch.cuda.is_available():\n",
        "            PATHWAY_MASK = PATHWAY_MASK.cuda()\n",
        "        ###\n",
        "        return(PATHWAY_MASK)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UYlruJ5z-cz1"
      },
      "outputs": [],
      "source": [
        "# Chunk 4\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.utils import check_random_state\n",
        "#from utils.resampling import nested_resampling\n",
        "#from utils.visualization import plot_survival_curves, plot_cv_results, plot_feature_importance\n",
        "#from preprocessing.data_container import DataContainer\n",
        "import pickle\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sksurv.util import Surv\n",
        "\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ModellingProcess():\n",
        "    \"\"\"\n",
        "    Class to handle the full modelling process for python  models with sklearn-interface. Includes data preparation, cross-validation,\n",
        "    hyperparameter tuning, model fitting, and result saving.\n",
        "    \"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the ModellingProcess instance with default attributes for cross-validation,\n",
        "        pipeline setup, and data storage.\n",
        "        \"\"\"\n",
        "        self.outer_cv = LeaveOneGroupOut()  # Outer cross-validation strategy: Scikit-learn's LeaveOneGroupOut\n",
        "        self.inner_cv = LeaveOneGroupOut()  # Inner cross-validation for hyperparameter tuning: Scikit-learn's LeaveOneGroupOut\n",
        "        self.ss = GridSearchCV  # Searchstrategy: Scikit-learn's GridSearchCV for hyperparameter tuning\n",
        "        self.pipe = None  # Scikit-learn Pipeline to handle preprocessing and model training\n",
        "        self.cmplt_model = None  # Final trained model after hyperparameter tuning\n",
        "        self.cmplt_pipeline = None  # Final pipeline after training\n",
        "        self.nrs = None  # Nested resampling results\n",
        "        self.X = None  # Training data features\n",
        "        self.y = None  # Training data labels\n",
        "        self.groups = None  # Cohort labels for cross-validation\n",
        "        self.path = None  # Directory path for saving model and results\n",
        "        self.fname_cv = None  # File name for saving cross-validation results\n",
        "\n",
        "    def prepare_survival_data(self, pdata):\n",
        "        status = pdata['BCR_STATUS'].astype(bool).values\n",
        "        time = pdata['MONTH_TO_BCR'].astype(float).values\n",
        "        y = Surv.from_arrays(\n",
        "            event=status,\n",
        "            time=time,\n",
        "            name_event='status',\n",
        "            name_time='time'\n",
        "        )\n",
        "        return y\n",
        "\n",
        "    # Note: Data path can be adapted here\n",
        "    def prepare_data(self, config, root):\n",
        "        self.config = config\n",
        "        self.X = pd.read_csv('/content/exprs_intersect.csv' , index_col=0)\n",
        "        self.pData = pd.read_csv('/content/merged_imputed_pData.csv', index_col=0)\n",
        "        self.y =self.prepare_survival_data(self.pData)\n",
        "        self.groups = np.array([idx.split('.')[0] for idx in self.X.index])\n",
        "\n",
        "        self.pData['AGE'] = pd.to_numeric(self.pData['AGE'], errors='coerce')\n",
        "\n",
        "        clin_data = self.pData.loc[:, self.config['clinical_covs']]\n",
        "        cat_cols = clin_data.select_dtypes(exclude=['number']).columns\n",
        "        num_cols = clin_data.select_dtypes(exclude=['object']).columns\n",
        "        clin_data_cat = clin_data.loc[:, cat_cols]\n",
        "        ohc = OneHotEncoder()\n",
        "        clin_data_cat = ohc.fit_transform(clin_data_cat)\n",
        "        clin_data_cat = pd.DataFrame.sparse.from_spmatrix(clin_data_cat, columns=ohc.get_feature_names_out()).set_index(self.X.index)\n",
        "        clin_data_num = clin_data.loc[:, num_cols]\n",
        "        self.X = pd.concat([clin_data_cat, clin_data_num, self.X], axis = 1)\n",
        "\n",
        "\n",
        "    def do_modelling(self, pipeline_steps, config):\n",
        "        \"\"\"\n",
        "        Executes the complete modeling process, including pipeline creation, nested resampling, and final model fitting.\n",
        "\n",
        "        Args:\n",
        "            pipeline_steps (list): List of (name, transformer) tuples for creating the pipeline --> objects need to adhere to scikit learn interface /API.\n",
        "            config (dict): Configuration for the modeling process, including parameters for cross-validation,\n",
        "                           hyperparameter tuning, and result saving.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Nested resampling results, final model, and complete, final pipeline.\n",
        "        \"\"\"\n",
        "        self._set_seed()\n",
        "\n",
        "        if config.get(\"params_mp\", None) is not None:\n",
        "            self.set_params(config['params_mp'])\n",
        "\n",
        "        if config.get(\"path\", None) is None or config.get(\"fname_cv\", None) is None:\n",
        "            logger.warning(\"Didn't get sufficient path info for saving cv-results\")\n",
        "        else:\n",
        "            self.path = config['path']\n",
        "            self.fname_cv = config['fname_cv']\n",
        "\n",
        "        err, mes = self._check_modelling_prerequs(pipeline_steps)\n",
        "        if err:\n",
        "           logger.error(\"Requirements setup error: %s\", mes)\n",
        "           raise Exception(mes)\n",
        "        else:\n",
        "            self.pipe = Pipeline(pipeline_steps)\n",
        "\n",
        "        param_grid, monitor, do_nested_resampling, refit_hp_tuning = self._get_config_vals(config)\n",
        "\n",
        "        try:\n",
        "            logger.info(\"Start model training...\")\n",
        "            logger.info(f\"Input data shape: X={self.X.shape}\")\n",
        "\n",
        "            if do_nested_resampling:\n",
        "                logger.info(\"Nested resampling...\")\n",
        "                self.nrs = nested_resampling(self.pipe, self.X, self.y, self.groups, param_grid, monitor, self.ss, self.outer_cv, self.inner_cv)\n",
        "                if (self.fname_cv is not None) and (self.path is not None):\n",
        "                    self.save_results(self.path, self.fname_cv, model = None, cv_results = self.nrs, pipe = None)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during nested resampling: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        if refit_hp_tuning:\n",
        "            try:\n",
        "                logger.info(\"Do HP Tuning for complete model; refit + set complete model\")\n",
        "                self.fit_cmplt_model(param_grid)\n",
        "                if (self.fname_cv is not None) and (self.path is not None):\n",
        "                    self.save_results(self.path, self.fname_cv, model = self.cmplt_model, cv_results = None, pipe = self.cmplt_pipeline)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error during complete model training: {str(e)}\")\n",
        "                raise\n",
        "        elif refit_hp_tuning is False and do_nested_resampling is False:\n",
        "            logger.info(\"Fit complete pipeline wo. HP tuning (on default params)\")\n",
        "            self.cmplt_pipeline = self.pipe.fit(self.X, self.y)\n",
        "            if (self.fname_cv is not None) and (self.path is not None):\n",
        "                    self.save_results(self.path, self.fname_cv, model = None, cv_results = None, pipe = self.cmplt_pipeline)\n",
        "\n",
        "        return self.nrs, self.cmplt_model, self.cmplt_pipeline\n",
        "\n",
        "\n",
        "    def fit_cmplt_model(self, param_grid, monitor = None):\n",
        "        \"\"\"\n",
        "        Performs hyperparameter tuning and fits the final model on all of group A.\n",
        "\n",
        "        Args:\n",
        "            param_grid (dict): Parameter grid for GridSearchCV.\n",
        "            monitor (optional): Additional monitor object for evaluation during training.\n",
        "\n",
        "        Returns:\n",
        "            tuple: The best model and the complete resampling result.\n",
        "        \"\"\"\n",
        "        logger.info(\"Do HP Tuning for complete model\")\n",
        "        res = self.ss(estimator=self.pipe, param_grid=param_grid, cv=self.outer_cv, n_jobs=4, verbose = 2, refit = True)\n",
        "        if monitor is not None:\n",
        "            res.fit(self.X, self.y, groups = self.groups, model__monitor = monitor)\n",
        "        else:\n",
        "            res.fit(self.X, self.y, groups = self.groups)\n",
        "        self.resampling_cmplt = res\n",
        "        self.cmplt_pipeline = res.best_estimator_\n",
        "        self.cmplt_model = res.best_estimator_.named_steps['model']\n",
        "        return res.best_estimator_.named_steps['model'], res\n",
        "\n",
        "\n",
        "    def save_results(self, path, fname, model = None, cv_results = None, pipe = None):\n",
        "        \"\"\"Save model and results\"\"\"\n",
        "        if model is None:\n",
        "            logger.warning(\"Won't save any model, since its not provided\")\n",
        "        else:\n",
        "        # Create directories\n",
        "            model_dir = os.path.join(path, 'model')\n",
        "            os.makedirs(model_dir, exist_ok=True)\n",
        "            model.model.to(torch.device('cpu'))\n",
        "            torch.save(model.model, os.path.join(model_dir, f\"{fname}.pth\"))\n",
        "            #with open(os.path.join(model_dir, f\"{fname}.pkl\"), 'wb') as f:\n",
        "            #    pickle.dump(model, f)\n",
        "            logger.info(f\"Saved model to {model_dir}\")\n",
        "\n",
        "        if cv_results is None:\n",
        "            logger.warning(\"Won't save any cv results, since its not provided\")\n",
        "        else:\n",
        "            results_dir = os.path.join(path, 'results')\n",
        "            os.makedirs(results_dir, exist_ok=True)\n",
        "            results_file = os.path.join(results_dir, f\"{fname}_cv.csv\")\n",
        "            pd.DataFrame(cv_results).to_csv(results_file)\n",
        "            logger.info(f\"Saved CV results to {results_file}\")\n",
        "\n",
        "\n",
        "    def _check_modelling_prerequs(self, pipeline_steps):\n",
        "        \"\"\"\n",
        "        Checks whether the necessary prerequisites for the modeling process are met (data is prepared + model exists in pipeline).\n",
        "\n",
        "        Args:\n",
        "            pipeline_steps (list): List of (name, transformer) tuples representing the steps in the pipeline.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A boolean indicating if an error was found (True if an error exists),\n",
        "                and a string message explaining the error.\n",
        "        \"\"\"\n",
        "        err = False\n",
        "        mes = \"\"\n",
        "        if self.X is None or self.y is None:\n",
        "            mes = mes + \"1) Please call prepare_data() with your preferred config or set X, y, and groups as attributes of your modelling process instance\"\n",
        "            err = True\n",
        "        if not any('model' in tup for tup in pipeline_steps):\n",
        "            mes = mes + \"2) Caution! Your pipline must include a named step for the model of the form ('model', <Instantiated Model Object>)\"\n",
        "            err = True\n",
        "        return err, mes\n",
        "\n",
        "    def _get_config_vals(self, config):\n",
        "        \"\"\"\n",
        "        Extracts configuration values from the provided modelling dictionary.\n",
        "\n",
        "        Args:\n",
        "            config (dict): Configuration dictionary with keys such as 'params_cv', 'monitor',\n",
        "                        'do_nested_resampling', and 'refit'.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Contains the following extracted values:\n",
        "                - param_grid (dict or None): Parameter grid for cross-validation.\n",
        "                - monitor (object or None): Optional monitor object for early stopping.\n",
        "                - do_nested_resampling (bool): Indicates whether nested resampling should be performed.\n",
        "                - refit_hp_tuning (bool): Indicates whether to refit the model with hyperparameter tuning.\n",
        "        \"\"\"\n",
        "        if config.get(\"params_cv\", None) is None:\n",
        "            logger.warning(\"No param grid for (nested) resampling detected - will fit model with default HPs and on complete data\")\n",
        "            return None, False, False\n",
        "        if config.get('monitor', None) is None:\n",
        "            logger.info(\"No additional monitoring detected\")\n",
        "        return config['params_cv'], config.get('monitor', None), config.get('do_nested_resampling', True) , config.get('refit', True)\n",
        "\n",
        "\n",
        "    def set_params(self, params):\n",
        "        \"\"\"\n",
        "        Set attributes of the current object based on a dictionary of parameters.\n",
        "        \"\"\"\n",
        "        for key, value in params.items():\n",
        "            setattr(self, key, value)\n",
        "\n",
        "\n",
        "    def _set_seed(self, seed = 1234):\n",
        "        \"\"\"\n",
        "        Set the random seed for NumPy, PyTorch, and scikit-learn to ensure reproducibility.\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        # PyTorch\n",
        "        torch.manual_seed(seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(seed)\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "        # Scikit-learn (and sksurv)\n",
        "        global random_state\n",
        "        random_state = check_random_state(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLvbmmOWKqti",
        "outputId": "df3e39fb-a39f-48bc-ac3d-69b4c593ae3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "# Setup paths\n",
        "PROJECT_ROOT =  os.getcwd()\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.append(PROJECT_ROOT)\n",
        "print(PROJECT_ROOT)\n",
        "import torch\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# If clinical_covs are adapted the network arch. must be changed as well!\n",
        "DATA_CONFIG = {\n",
        "    'clinical_covs' : [\"AGE\", \"TISSUE\", \"GLEASON_SCORE\", 'PRE_OPERATIVE_PSA']\n",
        "}\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "''' Net Settings'''\n",
        "In_Nodes = 13214 ###number of genes\n",
        "Pathway_Nodes = 143 ###number of pathways\n",
        "Hidden_Nodes = 100 ###number of hidden nodes\n",
        "Out_Nodes = 10 ###number of hidden nodes in the last hidden layer\n",
        "''' Initialize '''\n",
        "Learning_Rate = 0.01\n",
        "L2 = 0\n",
        "num_epochs = 3000 ###for grid search\n",
        "Num_EPOCHS = 15 ###for training\n",
        "###sub-network setup\n",
        "Dropout_Rate = [0.1, 0.1]\n",
        "''' load data and pathway '''\n",
        "pathway_mask = pd.read_csv(\"/content/pathway_mask.csv\", index_col = 0)\n",
        "\n",
        "\n",
        "# Model configuration\n",
        "MODEL_CONFIG = {\n",
        "    'params_cv': {\n",
        "        'model__Learning_Rate': [0.01],\n",
        "        'model__L2': [0.1],\n",
        "        'model__Num_Epochs': [10],\n",
        "        'model__dropout_rate': [0.4],\n",
        "        'model__Hidden_Nodes': [64],\n",
        "        'model__Out_Nodes': [32]\n",
        "        },\n",
        "    'refit': True,\n",
        "    'do_nested_resampling': True,\n",
        "    'path' : \"\",\n",
        "    'fname_cv' : 'test'}\n",
        "\n",
        "pipeline_steps = [('model', Cox_PASNet_Model(pathway_mask=pathway_mask, clin_covs=[\"AGE\", 'TISSUE_FFPE',\t'TISSUE_Fresh_frozen',\t'TISSUE_Snap_frozen', \"GLEASON_SCORE\", 'PRE_OPERATIVE_PSA']))]\n",
        "\n",
        "mp = ModellingProcess()\n",
        "mp.prepare_data(DATA_CONFIG, PROJECT_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYf2ECig9KeT",
        "outputId": "c3eccee0-f364-4e6f-95b9-64c7f77835a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "Loss in Eval:  tensor([4.1835], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1763], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1685], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1595], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1497], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1400], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1307], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1218], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1134], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1055], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0982], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "Loss in Eval:  tensor([4.1722], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1614], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1508], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1404], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1302], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1209], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1126], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1053], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0991], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0935], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0887], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "Loss in Eval:  tensor([4.1605], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1524], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1444], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1365], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1289], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1219], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1154], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1091], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1031], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0970], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0911], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "Loss in Eval:  tensor([4.1477], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1419], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1359], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1299], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1241], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1185], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1134], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1086], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1041], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0998], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0958], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "Loss in Eval:  tensor([4.1968], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1867], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1770], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1676], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1583], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1493], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1408], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1327], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1249], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1174], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1103], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "Loss in Eval:  tensor([4.0003], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9982], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9962], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9941], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9914], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9885], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9853], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9821], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9788], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9753], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9716], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "Loss in Eval:  tensor([4.1053], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0973], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0895], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0819], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0746], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0677], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0614], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0553], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0494], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0433], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0373], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "Loss in Eval:  tensor([4.0653], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0650], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0643], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0629], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0606], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0579], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0547], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0513], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0478], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0441], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0406], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
            "Loss in Eval:  tensor([4.1377], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1301], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1225], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1149], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.1071], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0992], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0913], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0835], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0758], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0681], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0607], device='cuda:0', grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:__main__:Won't save any model, since its not provided\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 9 folds for each of 1 candidates, totalling 9 fits\n",
            "Loss in Eval:  tensor([4.0311], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0235], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0155], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0078], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([4.0008], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9948], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9895], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9848], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9803], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "Loss in Eval:  tensor([3.9759], device='cuda:0', grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:__main__:Won't save any cv results, since its not provided\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in Eval:  tensor([3.9715], device='cuda:0', grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "({'mean_score': 0.6471213,\n",
              "  'std_score': 0.08144436,\n",
              "  'fold_results': [{'test_cohort': 'Atlanta_2014_Long',\n",
              "    'test_score': array(0.66639453, dtype=float32),\n",
              "    'best_params': {'model__Hidden_Nodes': 64,\n",
              "     'model__L2': 0.1,\n",
              "     'model__Learning_Rate': 0.01,\n",
              "     'model__Num_Epochs': 10,\n",
              "     'model__Out_Nodes': 32,\n",
              "     'model__dropout_rate': 0.4},\n",
              "    'inner_cv_results': {'mean_fit_time': array([27.64560014]),\n",
              "     'std_fit_time': array([3.30183357]),\n",
              "     'mean_score_time': array([4.82461718]),\n",
              "     'std_score_time': array([4.31853154]),\n",
              "     'param_model__Hidden_Nodes': masked_array(data=[64],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__L2': masked_array(data=[0.1],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Learning_Rate': masked_array(data=[0.01],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Num_Epochs': masked_array(data=[10],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Out_Nodes': masked_array(data=[32],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__dropout_rate': masked_array(data=[0.4],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'params': [{'model__Hidden_Nodes': 64,\n",
              "       'model__L2': 0.1,\n",
              "       'model__Learning_Rate': 0.01,\n",
              "       'model__Num_Epochs': 10,\n",
              "       'model__Out_Nodes': 32,\n",
              "       'model__dropout_rate': 0.4}],\n",
              "     'split0_test_score': array([0.52450979]),\n",
              "     'split1_test_score': array([0.55374593]),\n",
              "     'split2_test_score': array([0.62355042]),\n",
              "     'split3_test_score': array([0.62068963]),\n",
              "     'split4_test_score': array([0.61888266]),\n",
              "     'split5_test_score': array([0.77688605]),\n",
              "     'split6_test_score': array([0.80723608]),\n",
              "     'split7_test_score': array([0.61054331]),\n",
              "     'mean_test_score': array([0.64200548]),\n",
              "     'std_test_score': array([0.09314531]),\n",
              "     'rank_test_score': array([1], dtype=int32)}},\n",
              "   {'test_cohort': 'Belfast_2018_Jain',\n",
              "    'test_score': array(0.53649235, dtype=float32),\n",
              "    'best_params': {'model__Hidden_Nodes': 64,\n",
              "     'model__L2': 0.1,\n",
              "     'model__Learning_Rate': 0.01,\n",
              "     'model__Num_Epochs': 10,\n",
              "     'model__Out_Nodes': 32,\n",
              "     'model__dropout_rate': 0.4},\n",
              "    'inner_cv_results': {'mean_fit_time': array([21.43821093]),\n",
              "     'std_fit_time': array([0.86490618]),\n",
              "     'mean_score_time': array([3.36186072]),\n",
              "     'std_score_time': array([0.95370257]),\n",
              "     'param_model__Hidden_Nodes': masked_array(data=[64],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__L2': masked_array(data=[0.1],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Learning_Rate': masked_array(data=[0.01],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Num_Epochs': masked_array(data=[10],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Out_Nodes': masked_array(data=[32],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__dropout_rate': masked_array(data=[0.4],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'params': [{'model__Hidden_Nodes': 64,\n",
              "       'model__L2': 0.1,\n",
              "       'model__Learning_Rate': 0.01,\n",
              "       'model__Num_Epochs': 10,\n",
              "       'model__Out_Nodes': 32,\n",
              "       'model__dropout_rate': 0.4}],\n",
              "     'split0_test_score': array([0.67537415]),\n",
              "     'split1_test_score': array([0.61074919]),\n",
              "     'split2_test_score': array([0.62845671]),\n",
              "     'split3_test_score': array([0.73354232]),\n",
              "     'split4_test_score': array([0.66565615]),\n",
              "     'split5_test_score': array([0.81380415]),\n",
              "     'split6_test_score': array([0.7935943]),\n",
              "     'split7_test_score': array([0.60247445]),\n",
              "     'mean_test_score': array([0.69045643]),\n",
              "     'std_test_score': array([0.07623077]),\n",
              "     'rank_test_score': array([1], dtype=int32)}},\n",
              "   {'test_cohort': 'CPC_GENE_2017_Fraser',\n",
              "    'test_score': array(0.58143324, dtype=float32),\n",
              "    'best_params': {'model__Hidden_Nodes': 64,\n",
              "     'model__L2': 0.1,\n",
              "     'model__Learning_Rate': 0.01,\n",
              "     'model__Num_Epochs': 10,\n",
              "     'model__Out_Nodes': 32,\n",
              "     'model__dropout_rate': 0.4},\n",
              "    'inner_cv_results': {'mean_fit_time': array([25.84881869]),\n",
              "     'std_fit_time': array([1.58236486]),\n",
              "     'mean_score_time': array([4.9894363]),\n",
              "     'std_score_time': array([4.47062478]),\n",
              "     'param_model__Hidden_Nodes': masked_array(data=[64],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__L2': masked_array(data=[0.1],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Learning_Rate': masked_array(data=[0.01],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Num_Epochs': masked_array(data=[10],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Out_Nodes': masked_array(data=[32],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__dropout_rate': masked_array(data=[0.4],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'params': [{'model__Hidden_Nodes': 64,\n",
              "       'model__L2': 0.1,\n",
              "       'model__Learning_Rate': 0.01,\n",
              "       'model__Num_Epochs': 10,\n",
              "       'model__Out_Nodes': 32,\n",
              "       'model__dropout_rate': 0.4}],\n",
              "     'split0_test_score': array([0.69931972]),\n",
              "     'split1_test_score': array([0.53013796]),\n",
              "     'split2_test_score': array([0.57850134]),\n",
              "     'split3_test_score': array([0.65412748]),\n",
              "     'split4_test_score': array([0.65136421]),\n",
              "     'split5_test_score': array([0.79935795]),\n",
              "     'split6_test_score': array([0.78054565]),\n",
              "     'split7_test_score': array([0.60677785]),\n",
              "     'mean_test_score': array([0.66251652]),\n",
              "     'std_test_score': array([0.08795959]),\n",
              "     'rank_test_score': array([1], dtype=int32)}},\n",
              "   {'test_cohort': 'CPGEA_2020_Li',\n",
              "    'test_score': array(0.62711865, dtype=float32),\n",
              "    'best_params': {'model__Hidden_Nodes': 64,\n",
              "     'model__L2': 0.1,\n",
              "     'model__Learning_Rate': 0.01,\n",
              "     'model__Num_Epochs': 10,\n",
              "     'model__Out_Nodes': 32,\n",
              "     'model__dropout_rate': 0.4},\n",
              "    'inner_cv_results': {'mean_fit_time': array([27.04247797]),\n",
              "     'std_fit_time': array([4.07472302]),\n",
              "     'mean_score_time': array([4.47813937]),\n",
              "     'std_score_time': array([4.03809266]),\n",
              "     'param_model__Hidden_Nodes': masked_array(data=[64],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__L2': masked_array(data=[0.1],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Learning_Rate': masked_array(data=[0.01],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Num_Epochs': masked_array(data=[10],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Out_Nodes': masked_array(data=[32],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__dropout_rate': masked_array(data=[0.4],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'params': [{'model__Hidden_Nodes': 64,\n",
              "       'model__L2': 0.1,\n",
              "       'model__Learning_Rate': 0.01,\n",
              "       'model__Num_Epochs': 10,\n",
              "       'model__Out_Nodes': 32,\n",
              "       'model__dropout_rate': 0.4}],\n",
              "     'split0_test_score': array([0.66748297]),\n",
              "     'split1_test_score': array([0.59005082]),\n",
              "     'split2_test_score': array([0.53583062]),\n",
              "     'split3_test_score': array([0.64890283]),\n",
              "     'split4_test_score': array([0.63317454]),\n",
              "     'split5_test_score': array([0.74157304]),\n",
              "     'split6_test_score': array([0.76275206]),\n",
              "     'split7_test_score': array([0.60086066]),\n",
              "     'mean_test_score': array([0.64757844]),\n",
              "     'std_test_score': array([0.0713135]),\n",
              "     'rank_test_score': array([1], dtype=int32)}},\n",
              "   {'test_cohort': 'CamCap_2016_Ross_Adams',\n",
              "    'test_score': array(0.64890283, dtype=float32),\n",
              "    'best_params': {'model__Hidden_Nodes': 64,\n",
              "     'model__L2': 0.1,\n",
              "     'model__Learning_Rate': 0.01,\n",
              "     'model__Num_Epochs': 10,\n",
              "     'model__Out_Nodes': 32,\n",
              "     'model__dropout_rate': 0.4},\n",
              "    'inner_cv_results': {'mean_fit_time': array([24.53030768]),\n",
              "     'std_fit_time': array([1.87699063]),\n",
              "     'mean_score_time': array([4.91620752]),\n",
              "     'std_score_time': array([4.87033012]),\n",
              "     'param_model__Hidden_Nodes': masked_array(data=[64],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__L2': masked_array(data=[0.1],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Learning_Rate': masked_array(data=[0.01],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Num_Epochs': masked_array(data=[10],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Out_Nodes': masked_array(data=[32],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__dropout_rate': masked_array(data=[0.4],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'params': [{'model__Hidden_Nodes': 64,\n",
              "       'model__L2': 0.1,\n",
              "       'model__Learning_Rate': 0.01,\n",
              "       'model__Num_Epochs': 10,\n",
              "       'model__Out_Nodes': 32,\n",
              "       'model__dropout_rate': 0.4}],\n",
              "     'split0_test_score': array([0.63129252]),\n",
              "     'split1_test_score': array([0.52941179]),\n",
              "     'split2_test_score': array([0.62377852]),\n",
              "     'split3_test_score': array([0.62667263]),\n",
              "     'split4_test_score': array([0.61888266]),\n",
              "     'split5_test_score': array([0.80898875]),\n",
              "     'split6_test_score': array([0.74673784]),\n",
              "     'split7_test_score': array([0.58364713]),\n",
              "     'mean_test_score': array([0.64617648]),\n",
              "     'std_test_score': array([0.08367563]),\n",
              "     'rank_test_score': array([1], dtype=int32)}},\n",
              "   {'test_cohort': 'CancerMap_2017_Luca',\n",
              "    'test_score': array(0.6175834, dtype=float32),\n",
              "    'best_params': {'model__Hidden_Nodes': 64,\n",
              "     'model__L2': 0.1,\n",
              "     'model__Learning_Rate': 0.01,\n",
              "     'model__Num_Epochs': 10,\n",
              "     'model__Out_Nodes': 32,\n",
              "     'model__dropout_rate': 0.4},\n",
              "    'inner_cv_results': {'mean_fit_time': array([23.04097658]),\n",
              "     'std_fit_time': array([1.67198646]),\n",
              "     'mean_score_time': array([4.4329634]),\n",
              "     'std_score_time': array([4.30662939]),\n",
              "     'param_model__Hidden_Nodes': masked_array(data=[64],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__L2': masked_array(data=[0.1],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Learning_Rate': masked_array(data=[0.01],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Num_Epochs': masked_array(data=[10],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Out_Nodes': masked_array(data=[32],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__dropout_rate': masked_array(data=[0.4],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'params': [{'model__Hidden_Nodes': 64,\n",
              "       'model__L2': 0.1,\n",
              "       'model__Learning_Rate': 0.01,\n",
              "       'model__Num_Epochs': 10,\n",
              "       'model__Out_Nodes': 32,\n",
              "       'model__dropout_rate': 0.4}],\n",
              "     'split0_test_score': array([0.66911566]),\n",
              "     'split1_test_score': array([0.55047202]),\n",
              "     'split2_test_score': array([0.65146577]),\n",
              "     'split3_test_score': array([0.58652991]),\n",
              "     'split4_test_score': array([0.65308255]),\n",
              "     'split5_test_score': array([0.76243979]),\n",
              "     'split6_test_score': array([0.78410441]),\n",
              "     'split7_test_score': array([0.60193652]),\n",
              "     'mean_test_score': array([0.65739333]),\n",
              "     'std_test_score': array([0.07649415]),\n",
              "     'rank_test_score': array([1], dtype=int32)}},\n",
              "   {'test_cohort': 'DKFZ_2018_Gerhauser',\n",
              "    'test_score': array(0.8025682, dtype=float32),\n",
              "    'best_params': {'model__Hidden_Nodes': 64,\n",
              "     'model__L2': 0.1,\n",
              "     'model__Learning_Rate': 0.01,\n",
              "     'model__Num_Epochs': 10,\n",
              "     'model__Out_Nodes': 32,\n",
              "     'model__dropout_rate': 0.4},\n",
              "    'inner_cv_results': {'mean_fit_time': array([25.11074561]),\n",
              "     'std_fit_time': array([1.5599307]),\n",
              "     'mean_score_time': array([4.86990091]),\n",
              "     'std_score_time': array([4.0287525]),\n",
              "     'param_model__Hidden_Nodes': masked_array(data=[64],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__L2': masked_array(data=[0.1],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Learning_Rate': masked_array(data=[0.01],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Num_Epochs': masked_array(data=[10],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Out_Nodes': masked_array(data=[32],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__dropout_rate': masked_array(data=[0.4],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'params': [{'model__Hidden_Nodes': 64,\n",
              "       'model__L2': 0.1,\n",
              "       'model__Learning_Rate': 0.01,\n",
              "       'model__Num_Epochs': 10,\n",
              "       'model__Out_Nodes': 32,\n",
              "       'model__dropout_rate': 0.4}],\n",
              "     'split0_test_score': array([0.6859864]),\n",
              "     'split1_test_score': array([0.56082064]),\n",
              "     'split2_test_score': array([0.56026059]),\n",
              "     'split3_test_score': array([0.60258698]),\n",
              "     'split4_test_score': array([0.67920583]),\n",
              "     'split5_test_score': array([0.6240797]),\n",
              "     'split6_test_score': array([0.75385529]),\n",
              "     'split7_test_score': array([0.60677785]),\n",
              "     'mean_test_score': array([0.63419666]),\n",
              "     'std_test_score': array([0.06297826]),\n",
              "     'rank_test_score': array([1], dtype=int32)}},\n",
              "   {'test_cohort': 'MSKCC_2010_Taylor',\n",
              "    'test_score': array(0.76156586, dtype=float32),\n",
              "    'best_params': {'model__Hidden_Nodes': 64,\n",
              "     'model__L2': 0.1,\n",
              "     'model__Learning_Rate': 0.01,\n",
              "     'model__Num_Epochs': 10,\n",
              "     'model__Out_Nodes': 32,\n",
              "     'model__dropout_rate': 0.4},\n",
              "    'inner_cv_results': {'mean_fit_time': array([22.29289424]),\n",
              "     'std_fit_time': array([1.55253743]),\n",
              "     'mean_score_time': array([4.20728725]),\n",
              "     'std_score_time': array([4.05408334]),\n",
              "     'param_model__Hidden_Nodes': masked_array(data=[64],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__L2': masked_array(data=[0.1],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Learning_Rate': masked_array(data=[0.01],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Num_Epochs': masked_array(data=[10],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Out_Nodes': masked_array(data=[32],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__dropout_rate': masked_array(data=[0.4],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'params': [{'model__Hidden_Nodes': 64,\n",
              "       'model__L2': 0.1,\n",
              "       'model__Learning_Rate': 0.01,\n",
              "       'model__Num_Epochs': 10,\n",
              "       'model__Out_Nodes': 32,\n",
              "       'model__dropout_rate': 0.4}],\n",
              "     'split0_test_score': array([0.67074829]),\n",
              "     'split1_test_score': array([0.54992735]),\n",
              "     'split2_test_score': array([0.60749185]),\n",
              "     'split3_test_score': array([0.58876002]),\n",
              "     'split4_test_score': array([0.64158827]),\n",
              "     'split5_test_score': array([0.65093112]),\n",
              "     'split6_test_score': array([0.77528089]),\n",
              "     'split7_test_score': array([0.5831092]),\n",
              "     'mean_test_score': array([0.63347962]),\n",
              "     'std_test_score': array([0.06524974]),\n",
              "     'rank_test_score': array([1], dtype=int32)}},\n",
              "   {'test_cohort': 'Stockholm_2016_Ross_Adams',\n",
              "    'test_score': array(0.58203334, dtype=float32),\n",
              "    'best_params': {'model__Hidden_Nodes': 64,\n",
              "     'model__L2': 0.1,\n",
              "     'model__Learning_Rate': 0.01,\n",
              "     'model__Num_Epochs': 10,\n",
              "     'model__Out_Nodes': 32,\n",
              "     'model__dropout_rate': 0.4},\n",
              "    'inner_cv_results': {'mean_fit_time': array([24.035357]),\n",
              "     'std_fit_time': array([1.77498543]),\n",
              "     'mean_score_time': array([4.49173]),\n",
              "     'std_score_time': array([4.10047853]),\n",
              "     'param_model__Hidden_Nodes': masked_array(data=[64],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__L2': masked_array(data=[0.1],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Learning_Rate': masked_array(data=[0.01],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Num_Epochs': masked_array(data=[10],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__Out_Nodes': masked_array(data=[32],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'param_model__dropout_rate': masked_array(data=[0.4],\n",
              "                  mask=[False],\n",
              "            fill_value='?',\n",
              "                 dtype=object),\n",
              "     'params': [{'model__Hidden_Nodes': 64,\n",
              "       'model__L2': 0.1,\n",
              "       'model__Learning_Rate': 0.01,\n",
              "       'model__Num_Epochs': 10,\n",
              "       'model__Out_Nodes': 32,\n",
              "       'model__dropout_rate': 0.4}],\n",
              "     'split0_test_score': array([0.67673469]),\n",
              "     'split1_test_score': array([0.56463325]),\n",
              "     'split2_test_score': array([0.6563518]),\n",
              "     'split3_test_score': array([0.64049953]),\n",
              "     'split4_test_score': array([0.64681298]),\n",
              "     'split5_test_score': array([0.61844957]),\n",
              "     'split6_test_score': array([0.7977528]),\n",
              "     'split7_test_score': array([0.75385529]),\n",
              "     'mean_test_score': array([0.66938624]),\n",
              "     'std_test_score': array([0.06959581]),\n",
              "     'rank_test_score': array([1], dtype=int32)}}]},\n",
              " Cox_PASNet_Model(Hidden_Nodes=64, In_Nodes=6094, L2=0.1, Num_Epochs=10,\n",
              "                  Out_Nodes=32, Pathway_Nodes=143,\n",
              "                  clin_covs=['AGE', 'TISSUE_FFPE', 'TISSUE_Fresh_frozen',\n",
              "                             'TISSUE_Snap_frozen', 'GLEASON_SCORE',\n",
              "                             'PRE_OPERATIVE_PSA'],\n",
              "                  pathway_mask=                                     ENSG00000000419  ENSG00000000938  \\\n",
              " M5890                                              0                0   \n",
              " M5891                                              0                0   \n",
              " M5892                                              0                0   \n",
              " M5893                                              0                0   \n",
              " M5895                                              0                0   \n",
              " ...                                              ...              ...   \n",
              " XU_HGF_TARGETS_INDUCED_BY_AKT1_6HR                 0                0   \n",
              " XU_HGF_TARGETS_R...\n",
              " XU_HGF_TARGETS_REPRESSED_BY_AKT1_UP                0                0   \n",
              " YEGNASUBRAMANIAN_PROSTATE_CANCER                   0                0   \n",
              " YEMELYANOV_GR_TARGETS_DN                           0                0   \n",
              " \n",
              "                                      ENSG00000277443  ENSG00000278540  \n",
              " M5890                                              1                0  \n",
              " M5891                                              0                0  \n",
              " M5892                                              0                0  \n",
              " M5893                                              1                0  \n",
              " M5895                                              0                0  \n",
              " ...                                              ...              ...  \n",
              " XU_HGF_TARGETS_INDUCED_BY_AKT1_6HR                 0                0  \n",
              " XU_HGF_TARGETS_REPRESSED_BY_AKT1_DN                0                0  \n",
              " XU_HGF_TARGETS_REPRESSED_BY_AKT1_UP                0                0  \n",
              " YEGNASUBRAMANIAN_PROSTATE_CANCER                   0                0  \n",
              " YEMELYANOV_GR_TARGETS_DN                           0                0  \n",
              " \n",
              " [143 rows x 6094 columns]),\n",
              " Pipeline(steps=[('model',\n",
              "                  Cox_PASNet_Model(Hidden_Nodes=64, In_Nodes=6094, L2=0.1,\n",
              "                                   Num_Epochs=10, Out_Nodes=32,\n",
              "                                   Pathway_Nodes=143,\n",
              "                                   clin_covs=['AGE', 'TISSUE_FFPE',\n",
              "                                              'TISSUE_Fresh_frozen',\n",
              "                                              'TISSUE_Snap_frozen',\n",
              "                                              'GLEASON_SCORE',\n",
              "                                              'PRE_OPERATIVE_PSA'],\n",
              "                                   pathway_mask=                                     ENSG00000000419  ENSG00000000938  \\\n",
              " M5890                                              0                0   \n",
              " M5891                                              0                0   \n",
              " M5892                                              0                0   \n",
              " M5893                                              0                0   \n",
              " M5895                                              0                0   \n",
              " ...                                              ...              ...   \n",
              " XU_HGF_TARGETS_INDUCED_BY_A...\n",
              " XU_HGF_TARGETS_REPRESSED_BY_AKT1_UP                0                0   \n",
              " YEGNASUBRAMANIAN_PROSTATE_CANCER                   0                0   \n",
              " YEMELYANOV_GR_TARGETS_DN                           0                0   \n",
              " \n",
              "                                      ENSG00000277443  ENSG00000278540  \n",
              " M5890                                              1                0  \n",
              " M5891                                              0                0  \n",
              " M5892                                              0                0  \n",
              " M5893                                              1                0  \n",
              " M5895                                              0                0  \n",
              " ...                                              ...              ...  \n",
              " XU_HGF_TARGETS_INDUCED_BY_AKT1_6HR                 0                0  \n",
              " XU_HGF_TARGETS_REPRESSED_BY_AKT1_DN                0                0  \n",
              " XU_HGF_TARGETS_REPRESSED_BY_AKT1_UP                0                0  \n",
              " YEGNASUBRAMANIAN_PROSTATE_CANCER                   0                0  \n",
              " YEMELYANOV_GR_TARGETS_DN                           0                0  \n",
              " \n",
              " [143 rows x 6094 columns]))]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mp.do_modelling(pipeline_steps, MODEL_CONFIG)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
