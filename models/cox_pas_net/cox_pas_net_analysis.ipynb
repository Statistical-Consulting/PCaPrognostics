{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Setup directories\n",
    "RESULTS_DIR = os.path.join(os.getcwd(), 'results')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Imports\n",
    "from preprocessing.data_container import DataContainer\n",
    "from utils.evaluation import cindex_score\n",
    "from models.modelling_process import ModellingProcess\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from utils.evaluation import EarlyStoppingMonitor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from models.cox_pas_net_model import Cox_PASNet_Model, Cox_PASNet\n",
    "import torch\n",
    "\n",
    "def load_all_results(results_path): \n",
    "    # Get a list of all CSV files in the \"results\" folder\n",
    "    csv_files = [os.path.join(results_path, file) for file in os.listdir(results_path) if file.endswith('.csv')]\n",
    "\n",
    "    # Read all CSV files, add a \"name\" column, and combine them into one dataframe\n",
    "    combined_data = pd.concat(\n",
    "        [\n",
    "            # Read each CSV file and add a \"name\" column with the file name\n",
    "            pd.read_csv(file).assign(model=os.path.basename(file)) for file in csv_files\n",
    "        ],\n",
    "        ignore_index=True  # Reset the index in the combined dataframe\n",
    "    )\n",
    "    combined_data = combined_data.loc[:, ['model', 'mean_score' ,'std_score']]\n",
    "    combined_data = combined_data.groupby('model', as_index=False).agg(mean=('mean_score', 'mean'), sd = ('std_score', 'mean'))\n",
    "    # View the combined data\n",
    "    return combined_data\n",
    "\n",
    "# Not necessary due to different sd structure\n",
    "# def aggregate_results(results):\n",
    "#     results_aggr = results.groupby('model', as_index=False).agg(mean=('ci', 'mean'), sd=('ci', 'std'))\n",
    "#     return results_aggr\n",
    "\n",
    "\n",
    "# TODO: Ergbebnisse aus Test und Nested reampling kombiniernen\n",
    "def combine_results(results_nstd, results_test_1, results_test_2):\n",
    "    pass\n",
    "\n",
    "\n",
    "# TODO: Dataframe erstellen: Spalte 1: Name des Feautres, Spalte 2: Wert\n",
    "# -------------------- functions to load feat. imp from model\n",
    "def load_feat_imp(model_path):\n",
    "    with open(model_path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    # Cat boost specific\n",
    "    #print(model)\n",
    "    # bei den Modellen die keine eigene Modellklasse von uns haben, muss man gucken wie der library interne Aufruf ist\n",
    "    imps = model.model.get_feature_importance()\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "    'feature': model.model.feature_names_,\n",
    "    'value': imps\n",
    "    })\n",
    "    \n",
    "    df = df.sort_values(by = \"value\", ascending=False)\n",
    "    df = df[df.loc[: , 'value'] > 0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_model(model_path): \n",
    "    with open(model_path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "# --------------------- get test perf \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def get_weights(model_path):    \n",
    "    DATA_CONFIG = {\n",
    "        'use_pca': False,\n",
    "        'pca_threshold': 0.85,\n",
    "        'use_imputed': True,\n",
    "        'select_random' : False, \n",
    "        'use_cohorts': False, \n",
    "        # Muss je nach algo angepasst werden; CatBoost eig der einzige der keines braucht, bei den anderen auf True setzen\n",
    "        'requires_ohenc' : True, \n",
    "        'gene_type' : 'intersection',\n",
    "        'clinical_covs' : [\"AGE\", \"TISSUE\", \"GLEASON_SCORE\", 'PRE_OPERATIVE_PSA'],\n",
    "        'only_pDta' : False\n",
    "    }\n",
    "\n",
    "        \n",
    "    net = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    pathway_mask = pd.read_csv(\"pathway_mask.csv\", index_col = 0)\n",
    "    \n",
    "    mp = ModellingProcess()\n",
    "    mp.prepare_data(DATA_CONFIG, PROJECT_ROOT)\n",
    "    model_hull = Cox_PASNet_Model(pathway_mask= pathway_mask, clin_covs=['AGE', 'TISSUE_FFPE', 'TISSUE_Fresh_frozen',\n",
    "                        'TISSUE_Snap_frozen', 'GLEASON_SCORE',\n",
    "                        'PRE_OPERATIVE_PSA'])\n",
    "    model_hull.model = net\n",
    "    model_hull.is_fitted_ = True\n",
    "    \n",
    "    \n",
    "    genes, pData, ytime, yevent, \\\n",
    "        eval_x, eval_age, eval_ytime, eval_yevent = model_hull._prepare_data(mp.X, mp.y, 0.1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    w_sc1 = net.sc1.weight.data.cpu().detach().numpy()\n",
    "    w_sc2 = net.sc2.weight.data.cpu().detach().numpy()\n",
    "    w_sc3 = net.sc3.weight.data.cpu().detach().numpy()\n",
    "    w_sc4 = net.sc4.weight.data.cpu().detach().numpy()\n",
    "    np.savetxt(\"weights/w_sc1.csv\", w_sc1, delimiter = \",\")\n",
    "    np.savetxt(\"weights/w_sc2.csv\", w_sc2, delimiter = \",\")\n",
    "    np.savetxt(\"weights/w_sc3.csv\", w_sc3, delimiter = \",\")\n",
    "    np.savetxt(\"weights/w_sc4.csv\", w_sc4, delimiter = \",\")\n",
    "\n",
    "    pathway_node = net.tanh(net.sc1(genes))\n",
    "    hidden_node = net.tanh(net.sc2(pathway_node))\n",
    "    hidden_2_node = net.tanh(net.sc3(hidden_node))\n",
    "    x_cat = torch.cat((hidden_2_node, pData), 1)\n",
    "    lin_pred = net.sc4(x_cat)\n",
    "\n",
    "    np.savetxt(\"weights/pathway_node.csv\", pathway_node.cpu().detach().numpy(), delimiter = \",\")\n",
    "    np.savetxt(\"weights/hidden_node.csv\", hidden_node.cpu().detach().numpy(), delimiter = \",\")\n",
    "    np.savetxt(\"weights/hidden_2_node.csv\", x_cat.cpu().detach().numpy(), delimiter = \",\")\n",
    "    np.savetxt(\"weights/lin_pred.csv\", lin_pred.cpu().detach().numpy(), delimiter = \",\") \n",
    "\n",
    "\n",
    "# Function to test performance of all models\n",
    "def test_perf_all_models(model_path):\n",
    "    files = os.listdir(model_path)\n",
    "\n",
    "    for file in files:\n",
    "        print(file)\n",
    "\n",
    "        contains_pData = bool(re.search(r\"pData\", file, re.IGNORECASE))\n",
    "        contains_intersection = bool(re.search(r\"inter|intersection\", file, re.IGNORECASE))\n",
    "        contains_imputed = bool(re.search(r\"imp|imputed|common\", file, re.IGNORECASE))\n",
    "        contains_aenc = bool(re.search(r\"aenc|auto|autoenc\", file, re.IGNORECASE))\n",
    "        contains_scores = bool(re.search(r\"score|scores\", file, re.IGNORECASE))\n",
    "\n",
    "        \n",
    "        DATA_CONFIG = {\n",
    "            'use_pca': False,\n",
    "            'pca_threshold': 0.85,\n",
    "            'use_imputed': True,\n",
    "            'select_random' : False, \n",
    "            'use_cohorts': False, \n",
    "            # Muss je nach algo angepasst werden; CatBoost eig der einzige der keines braucht, bei den anderen auf True setzen\n",
    "            'requires_ohenc' : True, \n",
    "        }\n",
    "\n",
    "        # Load data based on file type\n",
    "        if contains_intersection:\n",
    "            DATA_CONFIG['gene_type'] = 'intersection'\n",
    "        elif contains_imputed:\n",
    "            DATA_CONFIG['gene_type'] = 'common_genes'\n",
    "        elif contains_aenc:\n",
    "            DATA_CONFIG['gene_type'] = 'autoencoder'\n",
    "        elif contains_scores: \n",
    "            DATA_CONFIG['gene_type'] = 'scores'\n",
    "        if contains_pData:\n",
    "            DATA_CONFIG['clinical_covs'] = [\"AGE\", \"TISSUE\", \"GLEASON_SCORE\", 'PRE_OPERATIVE_PSA']\n",
    "        if contains_pData and not contains_intersection and not contains_imputed and not contains_aenc and not contains_scores: \n",
    "            DATA_CONFIG['only_pData'] = True\n",
    "            DATA_CONFIG['gene_type'] = None\n",
    "            \n",
    "        # model_path = os.path.join(model_path, file)\n",
    "        # #with open(model_path, 'rb') as file:\n",
    "        # model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        # print(model)\n",
    "        # #print(model.model)\n",
    "        # pathway_mask = pd.read_csv(\"pathway_mask.csv\", index_col = 0)\n",
    "        \n",
    "        # model_hull = Cox_PASNet_Model(pathway_mask= pathway_mask, clin_covs=['AGE', 'TISSUE_FFPE', 'TISSUE_Fresh_frozen',\n",
    "        #                     'TISSUE_Snap_frozen', 'GLEASON_SCORE',\n",
    "        #                     'PRE_OPERATIVE_PSA'])\n",
    "        \n",
    "        mp = ModellingProcess()\n",
    "        mp.prepare_test_data(DATA_CONFIG, PROJECT_ROOT)\n",
    "        X_cos, y_cos = mp.prepare_test_cohort_data(DATA_CONFIG, PROJECT_ROOT, mp.test_groups)\n",
    "                \n",
    "        # model_hull.model = model\n",
    "        # model_hull.is_fitted_ = True\n",
    "        # print(mp.y_test.info)        \n",
    "        # ci_cmplt = model_hull.score(X_cos[0], y_cos[0])\n",
    "        # print(ci_cmplt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_intersect_pdata_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 12:20:50,768 - INFO - Found clinical data specification\n",
      "2025-01-15 12:20:50,905 - INFO - Loaded data: 496 samples, 13221 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_cohort_1_patient_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 12:21:15,454 - INFO - Found clinical data specification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_cohort_1_patient_1\n",
      "<bound method DataFrame.info of Empty DataFrame\n",
      "Columns: [SAMPLE_ID, GSM_SAMPLE_ID, SRR_SAMPLE_ID, PAPER_SAMPLE_ID, SAMPLE_COUNT, AGE, STUDY, PLATFORM, TISSUE, SAMPLE_CLASS, SAMPLE_TYPE, SURGICAL_PROCEDURE, CLIN_TNM_STAGE, CLIN_T_STAGE, CLIN_T_STAGE_GROUP, CLIN_N_STAGE, CLIN_M_STAGE, PATH_TNM_STAGE, PATH_T_STAGE, PATH_T_STAGE_GROUP, PATH_N_STAGE, PATH_M_STAGE, GLEASON_SCORE, GLEASON_SCORE_1, GLEASON_SCORE_2, PRE_OPERATIVE_PSA, MONTH_TO_BCR, BCR_STATUS, MONTH_TO_LAST_FOLLOW_UP, OS_STATUS, MONTH_TO_DOD, DOD_STATUS, MONTH_TO_CEP, CEP_STATUS, PATIENT_ID]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 35 columns]>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 111 elements, new values have 0 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m models_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RESULTS_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtest_perf_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#model_path = os.path.join(RESULTS_DIR, 'model', 'results_intersect_pdata_model.pth')\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#get_weights(model_path)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 174\u001b[0m, in \u001b[0;36mtest_perf_all_models\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m    172\u001b[0m mp \u001b[38;5;241m=\u001b[39m ModellingProcess()\n\u001b[0;32m    173\u001b[0m mp\u001b[38;5;241m.\u001b[39mprepare_test_data(DATA_CONFIG, PROJECT_ROOT)\n\u001b[1;32m--> 174\u001b[0m X_cos, y_cos \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_test_cohort_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_CONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROJECT_ROOT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_groups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\laeti\\PCaPrognostics\\models\\modelling_process.py:57\u001b[0m, in \u001b[0;36mModellingProcess.prepare_test_cohort_data\u001b[1;34m(self, data_config, root, cohorts)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cohort \u001b[38;5;129;01min\u001b[39;00m cohorts: \n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cohort)\n\u001b[1;32m---> 57\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_test_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcohort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcohort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     X_cohs \u001b[38;5;241m=\u001b[39m X_cohs\u001b[38;5;241m.\u001b[39mappend(X)\n\u001b[0;32m     59\u001b[0m     y_cohs \u001b[38;5;241m=\u001b[39m y_cohs\u001b[38;5;241m.\u001b[39mappend(y)\n",
      "File \u001b[1;32mc:\\Users\\laeti\\PCaPrognostics\\preprocessing\\data_container.py:60\u001b[0m, in \u001b[0;36mDataContainer.load_test_data\u001b[1;34m(self, cohort)\u001b[0m\n\u001b[0;32m     58\u001b[0m clin_data \u001b[38;5;241m=\u001b[39m pdata\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclinical_covs\u001b[39m\u001b[38;5;124m'\u001b[39m]] \n\u001b[0;32m     59\u001b[0m clin_data\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pdata\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m---> 60\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m \u001b[38;5;241m=\u001b[39m pdata\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     61\u001b[0m cat_cols \u001b[38;5;241m=\u001b[39m clin_data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     62\u001b[0m num_cols \u001b[38;5;241m=\u001b[39m clin_data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[1;32mc:\\Users\\laeti\\PCaPrognostics\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\laeti\\PCaPrognostics\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\laeti\\PCaPrognostics\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\laeti\\PCaPrognostics\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 111 elements, new values have 0 elements"
     ]
    }
   ],
   "source": [
    "models_path = os.path.join(RESULTS_DIR, 'model')\n",
    "test_perf_all_models(model_path=models_path)\n",
    "#model_path = os.path.join(RESULTS_DIR, 'model', 'results_intersect_pdata_model.pth')\n",
    "#get_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_path = os.path.join(RESULTS_DIR, 'results')\n",
    "# results = load_all_results(results_path)\n",
    "# final_results_path = os.path.join(PROJECT_ROOT, 'results_modelling')\n",
    "# results.to_csv(os.path.join(final_results_path, 'CoxPasNet.csv'))\n",
    "\n",
    "# ACTUALLY: SAVE COMBINED RESULTS TO CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
