{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-10T16:37:05.137436Z",
     "start_time": "2024-11-10T16:37:01.505179Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Create timestamped results directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "BASE_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'models', timestamp)\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, 'results', timestamp)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Imports\n",
    "from preprocessing.data_container import DataContainer\n",
    "from models.deep_surv_model import DeepSurvModel\n",
    "from utils.evaluation import cindex_score\n",
    "\n",
    "# Setup logging\n",
    "log_file = os.path.join(RESULTS_DIR, 'training.log')\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check for CUDA\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "logger.info(f\"Using device: {device}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 17:37:05,135 - INFO - Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:37:57.527244Z",
     "start_time": "2024-11-10T16:37:07.481520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data configuration\n",
    "DATA_CONFIG = {\n",
    "    'use_pca': False,\n",
    "    'gene_type': 'intersection',\n",
    "    'use_imputed': True,\n",
    "    'use_cohorts': True\n",
    "}\n",
    "\n",
    "# Model configuration with or without CV\n",
    "USE_CV = True  # Set to False for direct training\n",
    "\n",
    "if USE_CV:\n",
    "    # Configuration for CV training\n",
    "    MODEL_CONFIG = {\n",
    "        'params_cv': {\n",
    "            'hidden_layers': [[32, 16], [64, 32], [32, 32, 16]],\n",
    "            'learning_rate': [0.001, 0.0001],\n",
    "            'batch_size': [32, 64],\n",
    "            'num_epochs': [100]\n",
    "        },\n",
    "        'use_cohort_cv': True,\n",
    "        'n_splits_inner': 5\n",
    "    }\n",
    "else:\n",
    "    # Configuration for direct training\n",
    "    MODEL_CONFIG = {\n",
    "        'hidden_layers': [32, 16],\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64,\n",
    "        'num_epochs': 100,\n",
    "        'device': device,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "# Save configurations\n",
    "config_file = os.path.join(RESULTS_DIR, 'config.json')\n",
    "import json\n",
    "with open(config_file, 'w') as f:\n",
    "    json.dump({\n",
    "        'data_config': DATA_CONFIG,\n",
    "        'model_config': MODEL_CONFIG,\n",
    "        'use_cv': USE_CV\n",
    "    }, f, indent=4)\n",
    "\n",
    "try:\n",
    "    # Create DataContainer and load data\n",
    "    logger.info(\"Loading data...\")\n",
    "    data_container = DataContainer(DATA_CONFIG, project_root=PROJECT_ROOT)\n",
    "    X, y = data_container.load_data()\n",
    "    \n",
    "    logger.info(f\"Loaded data with shape: X={X.shape}\")\n",
    "    \n",
    "    # Save feature names\n",
    "    feature_names = pd.DataFrame({'feature': X.columns})\n",
    "    feature_names.to_csv(os.path.join(RESULTS_DIR, 'feature_names.csv'), index=False)\n",
    "    \n",
    "    # Initialize DeepSurv\n",
    "    logger.info(\"Initializing DeepSurv model...\")\n",
    "    if not USE_CV:\n",
    "        deep_surv = DeepSurvModel(**MODEL_CONFIG)\n",
    "    else:\n",
    "        deep_surv = DeepSurvModel(device=device, random_state=42)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during initialization: {str(e)}\")\n",
    "    raise\n"
   ],
   "id": "93814a4225316185",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 17:37:07,489 - INFO - Loading data...\n",
      "2024-11-10 17:37:07,490 - INFO - Loading data...\n",
      "2024-11-10 17:37:55,030 - INFO - Loaded data: 1091 samples, 13214 features\n",
      "2024-11-10 17:37:57,463 - INFO - Loaded data with shape: X=(1091, 13214)\n",
      "2024-11-10 17:37:57,499 - INFO - Initializing DeepSurv model...\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:38:05.553043Z",
     "start_time": "2024-11-10T16:38:01.372491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    logger.info(\"Starting model training...\")\n",
    "    \n",
    "    if USE_CV:\n",
    "        logger.info(f\"Cross-validation config: {MODEL_CONFIG}\")\n",
    "        # Fit with CV\n",
    "        deep_surv.fit(\n",
    "            X=X,\n",
    "            y=y,\n",
    "            data_container=data_container,\n",
    "            **MODEL_CONFIG\n",
    "        )\n",
    "        \n",
    "        # Log CV results\n",
    "        cv_results = pd.DataFrame(deep_surv.cv_results_['cv_results'])\n",
    "        logger.info(\"\\nCross-validation results:\")\n",
    "        logger.info(f\"Mean c-index: {deep_surv.cv_results_['mean_score']:.3f} \"\n",
    "                   f\"Â± {deep_surv.cv_results_['std_score']:.3f}\")\n",
    "        \n",
    "        # Save detailed CV results\n",
    "        cv_results.to_csv(os.path.join(RESULTS_DIR, 'cv_results.csv'))\n",
    "        \n",
    "    else:\n",
    "        # Direct training without CV\n",
    "        X_train, y_train, X_val, y_val = data_container.get_train_val_split(X, y)\n",
    "        deep_surv.fit(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            validation_data=(X_val, y_val)\n",
    "        )\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_pred = deep_surv.predict(X_val)\n",
    "        val_score = cindex_score(y_val, val_pred)\n",
    "        logger.info(f\"\\nValidation c-index: {val_score:.3f}\")\n",
    "        \n",
    "    logger.info(\"Model training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during training: {str(e)}\")\n",
    "    raise"
   ],
   "id": "1da0586032a55605",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 17:38:01,375 - INFO - Starting model training...\n",
      "2024-11-10 17:38:01,377 - INFO - Cross-validation config: {'params_cv': {'hidden_layers': [[32, 16], [64, 32], [32, 32, 16]], 'learning_rate': [0.001, 0.0001], 'batch_size': [32, 64], 'num_epochs': [100]}, 'use_cohort_cv': True, 'n_splits_inner': 5}\n",
      "2024-11-10 17:38:01,378 - INFO - Starting DeepSurv training...\n",
      "2024-11-10 17:38:01,379 - INFO - Starting nested cross-validation for DeepSurv...\n",
      "2024-11-10 17:38:01,381 - INFO - Outer fold 1\n",
      "2024-11-10 17:38:05,289 - ERROR - Error during training: Model must be fitted before predicting\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model must be fitted before predicting",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCross-validation config: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mMODEL_CONFIG\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Fit with CV\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[43mdeep_surv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_container\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_container\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mMODEL_CONFIG\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Log CV results\u001B[39;00m\n\u001B[1;32m     15\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(deep_surv\u001B[38;5;241m.\u001B[39mcv_results_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcv_results\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/9. Semester/Consulting/Organization/PCaPrognostics/models/deep_surv_model.py:144\u001B[0m, in \u001B[0;36mDeepSurvModel.fit\u001B[0;34m(self, X, y, data_container, params_cv, use_cohort_cv, n_splits_inner, **kwargs)\u001B[0m\n\u001B[1;32m    136\u001B[0m cv \u001B[38;5;241m=\u001B[39m DeepSurvNestedCV(\n\u001B[1;32m    137\u001B[0m     n_splits_inner\u001B[38;5;241m=\u001B[39mn_splits_inner,\n\u001B[1;32m    138\u001B[0m     use_cohort_cv\u001B[38;5;241m=\u001B[39muse_cohort_cv,\n\u001B[1;32m    139\u001B[0m     random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state\n\u001B[1;32m    140\u001B[0m )\n\u001B[1;32m    142\u001B[0m groups \u001B[38;5;241m=\u001B[39m data_container\u001B[38;5;241m.\u001B[39mget_groups() \u001B[38;5;28;01mif\u001B[39;00m data_container \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 144\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv_results_ \u001B[38;5;241m=\u001B[39m \u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparam_grid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams_cv\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;66;03m# Train final model with best parameters\u001B[39;00m\n\u001B[1;32m    153\u001B[0m best_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv_results_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcv_results\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    155\u001B[0m     key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    156\u001B[0m )[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest_params\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/9. Semester/Consulting/Organization/PCaPrognostics/utils/resampling.py:316\u001B[0m, in \u001B[0;36mDeepSurvNestedCV.fit\u001B[0;34m(self, estimator, X, y, groups, param_grid)\u001B[0m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;66;03m# Train on fold\u001B[39;00m\n\u001B[1;32m    315\u001B[0m     inner_model \u001B[38;5;241m=\u001B[39m clone(estimator)\n\u001B[0;32m--> 316\u001B[0m     score, trained_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_fold\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43minner_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_inner_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_inner_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_inner_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_inner_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    324\u001B[0m     fold_scores\u001B[38;5;241m.\u001B[39mappend(score)\n\u001B[1;32m    326\u001B[0m inner_scores\u001B[38;5;241m.\u001B[39mappend({\n\u001B[1;32m    327\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m: params,\n\u001B[1;32m    328\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_score\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mmean(fold_scores),\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstd_score\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mstd(fold_scores)\n\u001B[1;32m    330\u001B[0m })\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/9. Semester/Consulting/Organization/PCaPrognostics/utils/resampling.py:267\u001B[0m, in \u001B[0;36mDeepSurvNestedCV._train_fold\u001B[0;34m(self, model, X_train, y_train, X_val, y_val, params)\u001B[0m\n\u001B[1;32m    264\u001B[0m model\u001B[38;5;241m.\u001B[39mnetwork\u001B[38;5;241m.\u001B[39mload_state_dict(best_weights)\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# Calculate validation score (c-index)\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m val_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    268\u001B[0m val_score \u001B[38;5;241m=\u001B[39m cindex_score(y_val, val_pred)\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m val_score, model\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Uni/Master/9. Semester/Consulting/Organization/PCaPrognostics/models/deep_surv_model.py:266\u001B[0m, in \u001B[0;36mDeepSurvModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Predict risk scores for samples in X\"\"\"\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_fitted:\n\u001B[0;32m--> 266\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel must be fitted before predicting\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    268\u001B[0m \u001B[38;5;66;03m# Scale features\u001B[39;00m\n\u001B[1;32m    269\u001B[0m X_scaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "\u001B[0;31mValueError\u001B[0m: Model must be fitted before predicting"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    # Save model\n",
    "    logger.info(\"Saving model...\")\n",
    "    model_name = f\"deep_surv_model_{timestamp}\"\n",
    "    deep_surv.save(MODEL_DIR, model_name)\n",
    "    \n",
    "    # Save training history\n",
    "    history_df = pd.DataFrame(deep_surv.training_history_)\n",
    "    history_df.to_csv(os.path.join(RESULTS_DIR, 'training_history.csv'))\n",
    "    \n",
    "    # Plot training history if available\n",
    "    if len(deep_surv.training_history_['train_loss']) > 0:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history_df['train_loss'], label='Training Loss')\n",
    "        if 'val_loss' in history_df.columns:\n",
    "            plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training History')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(RESULTS_DIR, 'training_history.png'))\n",
    "        plt.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error saving results: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Final summary logging\n",
    "logger.info(\"\\nDeep Survival Network training pipeline completed successfully!\")\n",
    "logger.info(f\"Results saved in: {RESULTS_DIR}\")\n",
    "logger.info(f\"Model saved in: {MODEL_DIR}\")\n",
    "\n",
    "# Calculate final c-index if possible\n",
    "try:\n",
    "    # Calculate per-cohort performance if cohort information is available\n",
    "    if hasattr(data_container, 'get_groups') and data_container.get_groups() is not None:\n",
    "        groups = data_container.get_groups()\n",
    "        print(\"\\nPerformance by cohort:\")\n",
    "        for cohort in np.unique(groups):\n",
    "            mask = groups == cohort\n",
    "            if sum(mask) > 0:\n",
    "                cohort_pred = deep_surv.predict(X[mask])\n",
    "                cohort_score = cindex_score(y[mask], cohort_pred)\n",
    "                print(f\"{cohort}: {cohort_score:.3f} (n={sum(mask)})\")\n",
    "    \n",
    "    # Calculate overall performance\n",
    "    full_pred = deep_surv.predict(X)\n",
    "    full_cindex = cindex_score(y, full_pred)\n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"C-index on full dataset: {full_cindex:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error calculating final C-index: {str(e)}\")"
   ],
   "id": "b96eadad910dc0fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
